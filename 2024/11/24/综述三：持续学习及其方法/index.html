<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>综述三：持续学习及其方法 | Model The World</title><meta name="author" content="Serge Wang"><meta name="copyright" content="Serge Wang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="持续学习（Continual Learning，CL），也称为终身学习（Lifelong Learning），指的是模型能够从持续不断的数据流中学习，并随着时间的推移不断适应和获得新知识，而不会遗忘先前学习的内容。持续学习面临的一个主要挑战是灾难性遗忘（Catastrophic Forgetting），即在学习新任务时，模型容易遗忘之前学习的任务。 为了应对这些挑战，提出了多种方法，这些方法可以根">
<meta property="og:type" content="article">
<meta property="og:title" content="综述三：持续学习及其方法">
<meta property="og:url" content="https://sergewang.github.io/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B8%89%EF%BC%9A%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0%E5%8F%8A%E5%85%B6%E6%96%B9%E6%B3%95/">
<meta property="og:site_name" content="Model The World">
<meta property="og:description" content="持续学习（Continual Learning，CL），也称为终身学习（Lifelong Learning），指的是模型能够从持续不断的数据流中学习，并随着时间的推移不断适应和获得新知识，而不会遗忘先前学习的内容。持续学习面临的一个主要挑战是灾难性遗忘（Catastrophic Forgetting），即在学习新任务时，模型容易遗忘之前学习的任务。 为了应对这些挑战，提出了多种方法，这些方法可以根">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://sergewang.github.io/images/mamba.png">
<meta property="article:published_time" content="2024-11-24T11:04:52.000Z">
<meta property="article:modified_time" content="2024-12-03T12:29:52.726Z">
<meta property="article:author" content="Serge Wang">
<meta property="article:tag" content="综述">
<meta property="article:tag" content="持续学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://sergewang.github.io/images/mamba.png"><link rel="shortcut icon" href="/img/newlogo.png"><link rel="canonical" href="https://sergewang.github.io/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B8%89%EF%BC%9A%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0%E5%8F%8A%E5%85%B6%E6%96%B9%E6%B3%95/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="IDUolVgWkW_cmu1mtW5hsxrrIjQfCHvq5hOTOkXeVNE"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        if (name && globalFn[key][name]) return
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?9dcb7eb7a8a6225c2b1f242f3b0894bf";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
btf.addGlobalFn('pjaxComplete', () => {
  _hmt.push(['_trackPageview',window.location.pathname])
}, 'baidu_analytics')
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-XERFYF0N5K"></script><script>window.dataLayer = window.dataLayer || []
function gtag(){dataLayer.push(arguments)}
gtag('js', new Date())
gtag('config', 'G-XERFYF0N5K')
btf.addGlobalFn('pjaxComplete', () => {
  gtag('config', 'G-XERFYF0N5K', {'page_path': window.location.pathname})
}, 'google_analytics')
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '综述三：持续学习及其方法',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-12-03 20:29:52'
}</script></head><body><div id="web_bg" style="background-image: url(/img/background.png);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/newlogo.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">81</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">48</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">24</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/images/mamba.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="/img/newlogo.png" alt="Logo"><span class="site-name">Model The World</span></a><a class="nav-page-title" href="/"><span class="site-name">综述三：持续学习及其方法</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">综述三：持续学习及其方法</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-11-24T11:04:52.000Z" title="发表于 2024-11-24 19:04:52">2024-11-24</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-12-03T12:29:52.726Z" title="更新于 2024-12-03 20:29:52">2024-12-03</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0/">持续学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p><strong>持续学习（Continual Learning，CL）</strong>，也称为<strong>终身学习（Lifelong Learning）</strong>，指的是模型能够从持续不断的数据流中学习，并随着时间的推移不断适应和获得新知识，而不会遗忘先前学习的内容。持续学习面临的一个主要挑战是<strong>灾难性遗忘（Catastrophic Forgetting）</strong>，即在学习新任务时，模型容易遗忘之前学习的任务。</p>
<p>为了应对这些挑战，提出了多种方法，这些方法可以根据它们如何处理遗忘、如何存储知识以及如何使用新数据进行分类。</p>
<p>下面是<strong>主要的持续学习方法</strong>，按它们所采用的主要策略进行组织：</p>
<h3 id="1-基于正则化的方法">1. <strong>基于正则化的方法</strong></h3>
<p>这些方法通过在损失函数中添加正则化项，来防止模型在学习新任务时改变对先前任务至关重要的权重。</p>
<ul>
<li>
<p><strong>弹性权重约束（EWC）</strong></p>
<ul>
<li><strong>关键特性</strong>：通过基于费舍尔信息矩阵对重要的权重进行二次惩罚，正则化先前任务的重要权重。</li>
<li><strong>目的</strong>：通过惩罚关键权重的变化，减少灾难性遗忘。</li>
</ul>
</li>
<li>
<p><strong>突触智能（SI）</strong></p>
<ul>
<li><strong>关键特性</strong>：在训练过程中动态跟踪网络权重对先前任务的重要性。</li>
<li><strong>目的</strong>：类似于EWC，通过在训练时添加惩罚项，防止权重发生剧烈变化。</li>
</ul>
</li>
<li>
<p><strong>记忆感知突触（MAS）</strong></p>
<ul>
<li><strong>关键特性</strong>：通过评估网络参数对先前任务的影响来衡量权重的重要性。</li>
<li><strong>目的</strong>：与EWC相似，但更加动态地计算权重的重要性。</li>
</ul>
</li>
<li>
<p><strong>渐进神经网络（PNN）</strong></p>
<ul>
<li><strong>关键特性</strong>：学习新任务时，添加新的神经网络模块，旧模块保持不变。</li>
<li><strong>目的</strong>：通过为每个新任务分配额外的模块，避免任务之间的干扰，同时保持对先前任务的记忆。</li>
</ul>
</li>
</ul>
<h3 id="2-基于回放的方法">2. <strong>基于回放的方法</strong></h3>
<p>这些方法通过存储部分先前的数据（或合成数据），并在学习新任务时回放这些数据，以保持对旧任务的记忆。</p>
<ul>
<li>
<p><strong>经验回放（ER）</strong></p>
<ul>
<li><strong>关键特性</strong>：存储先前的样本，并在学习新任务时回放这些样本。</li>
<li><strong>目的</strong>：通过重新学习过去任务的数据来减轻遗忘。</li>
</ul>
</li>
<li>
<p><strong>聚类和优先经验回放</strong></p>
<ul>
<li><strong>关键特性</strong>：这些方法优先选择一些最可能帮助保持先前知识的样本进行回放。</li>
<li><strong>目的</strong>：通过优先回放最重要的样本来提高回放策略的效率。</li>
</ul>
</li>
<li>
<p><strong>生成回放</strong></p>
<ul>
<li><strong>关键特性</strong>：使用生成模型（如GAN或VAE）生成先前任务的数据，而不是直接存储实际样本。</li>
<li><strong>目的</strong>：避免存储大量数据，同时通过生成与原始数据相似的样本来回顾旧任务。</li>
</ul>
</li>
<li>
<p><strong>记忆回放（Memory Replay）</strong></p>
<ul>
<li><strong>关键特性</strong>：与存储原始数据不同，这些方法存储的是先前经验的抽象表示或特征。</li>
<li><strong>目的</strong>：通过回放压缩版本的数据来减少内存需求。</li>
</ul>
</li>
</ul>
<h3 id="3-动态架构方法">3. <strong>动态架构方法</strong></h3>
<p>这些方法在网络架构上进行修改，随着新任务的学习，增加新的神经元或层，使模型能够适应新任务，而不会忘记旧任务。</p>
<ul>
<li>
<p><strong>渐进神经网络（PNN）</strong></p>
<ul>
<li><strong>关键特性</strong>：随着新任务的到来，增加新的列（即新的神经网络模块）。</li>
<li><strong>目的</strong>：通过为每个任务分配不同的网络部分来避免任务之间的干扰。</li>
</ul>
</li>
<li>
<p><strong>PathNet</strong></p>
<ul>
<li><strong>关键特性</strong>：学习在共享神经网络中优化路径，使每个新任务可以使用不同的路径。</li>
<li><strong>目的</strong>：在保持共享知识的同时，为每个任务分配专用路径。</li>
</ul>
</li>
<li>
<p><strong>网络扩展</strong></p>
<ul>
<li><strong>关键特性</strong>：随着新任务的到来，动态扩展模型，增加新的层或神经元。</li>
<li><strong>目的</strong>：通过增加网络的容量来适应新任务，而不会影响旧任务。</li>
</ul>
</li>
</ul>
<h3 id="4-元学习方法">4. <strong>元学习方法</strong></h3>
<p>元学习，也叫学习如何学习，帮助模型更快适应新任务，通常通过学习如何在学习过程中防止遗忘。</p>
<ul>
<li>
<p><strong>元经验回放（MER）</strong></p>
<ul>
<li><strong>关键特性</strong>：将元学习技术与经验回放结合，用于解决持续学习问题。</li>
<li><strong>目的</strong>：不仅帮助模型记住先前的任务，还帮助它快速适应新任务。</li>
</ul>
</li>
<li>
<p><strong>模型无关元学习（MAML）</strong></p>
<ul>
<li><strong>关键特性</strong>：训练模型以便从少量示例中快速学习，通过优化使模型能够快速适应新任务。</li>
<li><strong>目的</strong>：使模型在结合特定任务的微调后，更能快速适应新任务，从而减少灾难性遗忘。</li>
</ul>
</li>
<li>
<p><strong>Reptile</strong></p>
<ul>
<li><strong>关键特性</strong>：MAML的简化替代方法，它通过反复抽样任务来调整模型权重，使其更适应新任务。</li>
<li><strong>目的</strong>：改善模型对新任务的快速学习能力，减少遗忘。</li>
</ul>
</li>
</ul>
<h3 id="5-知识蒸馏方法">5. <strong>知识蒸馏方法</strong></h3>
<p>这些方法将知识从旧模型转移到新模型（或同一模型），以防止灾难性遗忘。</p>
<ul>
<li>
<p><strong>知识蒸馏</strong></p>
<ul>
<li><strong>关键特性</strong>：通过最小化旧模型和新模型输出之间的差异，将先前任务的知识转移到当前模型。</li>
<li><strong>目的</strong>：在学习新任务的同时帮助保持对旧任务的知识。</li>
</ul>
</li>
<li>
<p><strong>自我蒸馏</strong></p>
<ul>
<li><strong>关键特性</strong>：使用模型本身将知识蒸馏成更紧凑的形式，帮助模型保持有用的先前知识。</li>
<li><strong>目的</strong>：作为一种附加的正则化策略，防止遗忘。</li>
</ul>
</li>
</ul>
<h3 id="6-贝叶斯方法">6. <strong>贝叶斯方法</strong></h3>
<p>这些方法在学习过程中引入不确定性，以在学习新任务的同时保持对旧任务的知识。</p>
<ul>
<li>
<p><strong>贝叶斯神经网络</strong></p>
<ul>
<li><strong>关键特性</strong>：采用概率方法来建模不确定性，帮助避免灾难性遗忘，通过将参数视为分布来处理任务。</li>
<li><strong>目的</strong>：鼓励模型在学习新任务时对已学权重做出更保守的调整，减少遗忘。</li>
</ul>
</li>
<li>
<p><strong>变分持续学习（VCL）</strong></p>
<ul>
<li><strong>关键特性</strong>：使用变分推断来学习特定任务的参数，同时保持先前任务的知识。</li>
<li><strong>目的</strong>：通过将旧知识视为分布并将其纳入学习过程，防止灾难性遗忘。</li>
</ul>
</li>
</ul>
<h3 id="7-双重记忆模型">7. <strong>双重记忆模型</strong></h3>
<p>这些模型保持两种类型的记忆：一种用于当前任务学习，另一种用于存储重要的旧知识。</p>
<ul>
<li>
<p><strong>双重记忆网络</strong></p>
<ul>
<li><strong>关键特性</strong>：维护一个用于当前任务的快速访问记忆和一个用于长期存储旧任务知识的记忆。</li>
<li><strong>目的</strong>：使模型能够在学习新任务的同时保持对旧任务的记忆。</li>
</ul>
</li>
<li>
<p><strong>认知模型（例如，层次记忆网络）</strong></p>
<ul>
<li><strong>关键特性</strong>：以更生物启发的方式建模记忆，使用层次结构或结构化记忆来存储和访问知识。</li>
<li><strong>目的</strong>：帮助模型以更有组织和长期的方式存储知识，类似于人类如何保持记忆。</li>
</ul>
</li>
</ul>
<h3 id="8-其他混合方法">8. <strong>其他混合方法</strong></h3>
<p>这些方法结合了上述方法中的多种策略，以进一步改善持续学习过程。</p>
<ul>
<li>
<p><strong>课程学习与持续学习结合</strong></p>
<ul>
<li><strong>关键特性</strong>：使用任务的课程，从简单的任务开始，逐渐增加任务的复杂性，帮助模型更有效地学习。</li>
<li><strong>目的</strong>：帮助模型在先前知识的基础上进行学习，减少过渡到更复杂任务时的遗忘。</li>
</ul>
</li>
<li>
<p><strong>任务增量学习（TIL）</strong></p>
<ul>
<li><strong>关键特性</strong>：通过保持特定任务的知识，在不需要大量重训练的情况下，增量地学习多个任务。</li>
<li><strong>目的</strong>：保持多个任务的知识，同时避免任务之间的干扰。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="主要方法总结：">主要方法总结：</h3>
<ol>
<li><strong>正则化方法</strong>（EWC、SI、MAS）</li>
<li><strong>回放方法</strong>（经验回放、生成回放、记忆回放）</li>
<li><strong>动态架构方法</strong>（PNN、PathNet、网络扩展）</li>
<li><strong>元学习方法</strong>（MAML、MER、Reptile）</li>
<li><strong>知识蒸馏方法</strong>（自我蒸馏、迁移学习）</li>
<li><strong>贝叶斯方法</strong>（VCL、贝叶斯神经网络）</li>
<li><strong>双重记忆模型</strong>（层次记忆网络）</li>
<li><strong>混合方法</strong>（课程学习、任务增量学习）</li>
</ol>
<h3 id="总结：">总结：</h3>
<p>这些方法通过不同的策略解决持续学习中的各种挑战，如灾难性遗忘、模型适应性、内存需求等。每种方法都有其独特的优点，适用于不同的任务和场景。某些方法侧重于通过正则化防止过度更新旧任务的知识，另一些方法则通过存储旧任务的数据或生成旧任务的数据来保持知识，还有一些方法通过动态扩展网络架构或引入元学习来增强模型的适应性。</p>
<p>结合不同方法，通常可以进一步改善持续学习的效果，帮助模型在面对多个任务时保持高效学习能力，同时不遗忘已学的知识。</p>
<h2 id="论文">论文</h2>
<h3 id="Loss-of-Plasticity-in-Continual-Deep-Reinforcement-Learning-23-03">Loss of Plasticity in Continual Deep Reinforcement Learning (23/03)</h3>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2303.07507">论文地址</a><br>
核心思想：连续学习的能力在复杂和不断变化的世界中至关重要。本文描述了规范的基于值的深度强化学习（RL）方法在<strong>不同程度的非平稳性</strong>下的行为。特别是，我们证明了当深度RL学习代理在一系列Atari 2600游戏中循环时，它们会失去学习良好策略的能力。先前的研究以各种形式提及了这种现象——例如，可塑性丧失、隐性参数化不足、首因偏差和容量损失。我们在规模上密切研究了这一现象，并在几个具有不同维度（例如，游戏之间的相似性、游戏数量、每个游戏的帧数）的实验中分析了权重、梯度和激活如何随时间变化，其中一些实验跨越了 50 天和 20 亿次环境交互。我们的分析表明，网络的激活足迹变得更稀疏，导致梯度减小。我们研究了一种非常简单的缓解策略：串联 ReLU（CReLU）激活函数，并证明了它在促进不断变化的环境中持续学习方面的有效性。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://SergeWang.github.io">Serge Wang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://sergewang.github.io/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B8%89%EF%BC%9A%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0%E5%8F%8A%E5%85%B6%E6%96%B9%E6%B3%95/">https://sergewang.github.io/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B8%89%EF%BC%9A%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0%E5%8F%8A%E5%85%B6%E6%96%B9%E6%B3%95/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://SergeWang.github.io" target="_blank">Model The World</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%BB%BC%E8%BF%B0/">综述</a><a class="post-meta__tags" href="/tags/%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0/">持续学习</a></div><div class="post-share"><div class="social-share" data-image="/images/mamba.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B8%83%EF%BC%9ACNN%E6%A8%A1%E5%9E%8B/" title="综述七：CNN模型"><img class="cover" src="/images/mamba.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">综述七：CNN模型</div></div><div class="info-2"><div class="info-item-1">Here’s a list of major CNN (Convolutional Neural Network) variants ordered by the time of their publication. CNNs have evolved over the years to improve accuracy, reduce computational costs, and adapt to different domains.  1. LeNet (1998)  Key Idea: One of the first CNN architectures, designed for handwritten digit recognition (MNIST). It used convolutional layers followed by pooling and fully connected layers. Application: Digit classification. Notable Paper: Yann LeCun et al.,...</div></div></div></a><a class="pagination-related" href="/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B9%9D%EF%BC%9ALLM/" title="综述九：LLM"><img class="cover" src="/images/mamba.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">综述九：LLM</div></div><div class="info-2"><div class="info-item-1">提示（Prompts） Large Lanuage Models Can Self-Improve in Long-context Reasoning (24/10) 论文地址 核心思想：大型语言模型（LLM）在处理长上下文方面取得了实质性进展，但在长上下文推理方面仍存在困难。现有的方法通常涉及使用合成数据对LLM进行微调，这取决于人类专家的注释或GPT-4等高级模型，从而限制了进一步的进步。为了解决这个问题，研究了LLM在长上下文推理中自我改进的潜力，并提出了专门为此目的设计的SEALONG方法。这种方法很简单：对每个问题的多个输出进行采样，用最小贝叶斯风险对其进行评分，然后根据这些输出进行监督微调或偏好优化。在几个领先的LLM上进行的广泛实验证明了SEALONG的有效性，Llama-3.1-8B-Instruct的绝对提高了4.2分。此外，与依赖于人类专家或高级模型生成的数据的先前方法相比，SEALONG实现了更优的性能。我们预计，这项工作将为长期情景下的自我提升技术开辟新的途径，这对LLM的持续发展至关重要。 </div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B8%80%EF%BC%9ATransformer%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/" title="综述一：Transformer及其变体"><img class="cover" src="/images/transformer.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-24</div><div class="info-item-2">综述一：Transformer及其变体</div></div><div class="info-2"><div class="info-item-1">Transformer架构，因其自注意力机制而闻名，能够让模型根据输入序列中不同的标记之间的关系进行加权。这种机制消除了循环神经网络的需求，使得训练变得更加高效。自从2017年原始Transformer的提出以来，已经出现了多个变种，旨在优化性能、扩展其适用范围或解决一些挑战。以下是一些著名的Transformer变种，特别是那些专注于自注意力机制的： 1. 原始Transformer (Vanilla Transformer)  关键特性：原始Transformer架构包括一个编码器-解码器结构，采用自注意力机制。 目的：消除了递归神经网络的需求，使得模型训练更加并行化和高效。 自注意力机制：多头自注意力，通过计算输入序列中所有标记之间的关系来决定重要性。  2. BERT（双向编码器表示）  关键特性：BERT只使用Transformer的编码器部分，采用双向自注意力机制来捕获标记的左右上下文。 目的：通过掩蔽语言模型（MLM）进行预训练，并可以通过微调来提升在下游NLP任务中的表现。  3....</div></div></div></a><a class="pagination-related" href="/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B8%83%EF%BC%9ACNN%E6%A8%A1%E5%9E%8B/" title="综述七：CNN模型"><img class="cover" src="/images/mamba.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-24</div><div class="info-item-2">综述七：CNN模型</div></div><div class="info-2"><div class="info-item-1">Here’s a list of major CNN (Convolutional Neural Network) variants ordered by the time of their publication. CNNs have evolved over the years to improve accuracy, reduce computational costs, and adapt to different domains.  1. LeNet (1998)  Key Idea: One of the first CNN architectures, designed for handwritten digit recognition (MNIST). It used convolutional layers followed by pooling and fully connected layers. Application: Digit classification. Notable Paper: Yann LeCun et al.,...</div></div></div></a><a class="pagination-related" href="/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B9%9D%EF%BC%9ALLM/" title="综述九：LLM"><img class="cover" src="/images/mamba.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-24</div><div class="info-item-2">综述九：LLM</div></div><div class="info-2"><div class="info-item-1">提示（Prompts） Large Lanuage Models Can Self-Improve in Long-context Reasoning (24/10) 论文地址 核心思想：大型语言模型（LLM）在处理长上下文方面取得了实质性进展，但在长上下文推理方面仍存在困难。现有的方法通常涉及使用合成数据对LLM进行微调，这取决于人类专家的注释或GPT-4等高级模型，从而限制了进一步的进步。为了解决这个问题，研究了LLM在长上下文推理中自我改进的潜力，并提出了专门为此目的设计的SEALONG方法。这种方法很简单：对每个问题的多个输出进行采样，用最小贝叶斯风险对其进行评分，然后根据这些输出进行监督微调或偏好优化。在几个领先的LLM上进行的广泛实验证明了SEALONG的有效性，Llama-3.1-8B-Instruct的绝对提高了4.2分。此外，与依赖于人类专家或高级模型生成的数据的先前方法相比，SEALONG实现了更优的性能。我们预计，这项工作将为长期情景下的自我提升技术开辟新的途径，这对LLM的持续发展至关重要。 </div></div></div></a><a class="pagination-related" href="/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B9%9D%EF%BC%9AMamba%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/" title="综述九：Mamba及其变体"><img class="cover" src="/images/mamba.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-24</div><div class="info-item-2">综述九：Mamba及其变体</div></div><div class="info-2"><div class="info-item-1">SSM模型 Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention (20/06) 论文地址 核心思想：将自注意表示为核特征图的线性点积，并使用矩阵乘法的结合属性将复杂度从 O(N2)\mathcal{O}(N^2)O(N2) 减少到 O(N)\mathcal{O}(N)O(N) ，其中N是序列长度。我们证明，这个公式允许迭代实现，大大加速了自回归Transformers，并揭示了它们与循环神经网络的关系。(一种涉及循环的自我注意近似，可以看作是退化的线性SSM)  Hungry Hungry Hippos: Towards Language Modeling with State Space Models...</div></div></div></a><a class="pagination-related" href="/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%BA%8C%EF%BC%9ADiTs%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/" title="综述二：DiTs及其变体"><img class="cover" src="/images/SIT.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-24</div><div class="info-item-2">综述二：DiTs及其变体</div></div><div class="info-2"><div class="info-item-1">**DiT（去噪扩散Transformer模型）**是结合了Transformer架构和扩散模型的一类生成模型，特别专注于在扩散框架内的去噪过程。扩散模型通过逐步添加和去除噪声的过程来建模复杂的分布，近年来在生成任务中非常流行。 下面是一些著名的DiT变种，它们在不同方面扩展了原始的DiT模型： 1. DiT（原始版本）  关键特性：原始的DiT模型将Transformer架构与去噪扩散过程结合，利用Transformer的注意力机制改进生成质量和训练的可扩展性。 目的：生成高质量的图像，并与传统的卷积神经网络相比，提高训练效率。  2. DiT++（增强版DiT）  关键特性：DiT++是在原始DiT基础上进行增强的版本，可能包括模型架构的改进、训练方法的优化或额外的正则化技术。 目的：通过改进Transformer架构和扩散过程中的噪声调度，提升生成稳定性和性能。  3....</div></div></div></a><a class="pagination-related" href="/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%BA%94%EF%BC%9A%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%8F%8A%E5%85%B6%E5%88%86%E7%B1%BB/" title="综述五：强化学习及其分类"><img class="cover" src="/images/mamba.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-24</div><div class="info-item-2">综述五：强化学习及其分类</div></div><div class="info-2"><div class="info-item-1">强化学习的变种 强化学习（Reinforcement Learning，简称RL）是一种机器学习方法，其中代理（Agent）通过与环境的交互来学习做出决策。代理的目标是通过采取适当的行动，最大化长期累积的奖励。强化学习是一个广泛的领域，许多不同的变种和算法已被开发出来，以解决学习、探索和决策等不同方面的问题。 以下是强化学习的主要变种及其子类别：  1. 无模型 vs 有模型强化学习  无模型强化学习（Model-Free RL）：代理不构建或使用环境的动态模型，而是直接通过与环境的交互来学习。  示例：  Q学习（Q-Learning，包括表格化和深度Q学习） 策略梯度方法（例如，REINFORCE） Actor-Critic方法（例如A3C，PPO）     有模型强化学习（Model-Based RL）：代理试图学习环境的转移动态和奖励函数，并利用这些模型来做出更有信息量的决策。  示例：  Dyna-Q（Q学习与规划结合） World Models 蒙特卡洛树搜索（MCTS）       2....</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/newlogo.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Serge Wang</div><div class="author-info-description">今日事，今日毕</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">81</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">48</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">24</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/SergeWang"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/SergeWang" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:sergew027@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">Welcome to my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%9F%BA%E4%BA%8E%E6%AD%A3%E5%88%99%E5%8C%96%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">1.</span> <span class="toc-text">1. 基于正则化的方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%9F%BA%E4%BA%8E%E5%9B%9E%E6%94%BE%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text">2. 基于回放的方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%8A%A8%E6%80%81%E6%9E%B6%E6%9E%84%E6%96%B9%E6%B3%95"><span class="toc-number">3.</span> <span class="toc-text">3. 动态架构方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%85%83%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95"><span class="toc-number">4.</span> <span class="toc-text">4. 元学习方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F%E6%96%B9%E6%B3%95"><span class="toc-number">5.</span> <span class="toc-text">5. 知识蒸馏方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%96%B9%E6%B3%95"><span class="toc-number">6.</span> <span class="toc-text">6. 贝叶斯方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-%E5%8F%8C%E9%87%8D%E8%AE%B0%E5%BF%86%E6%A8%A1%E5%9E%8B"><span class="toc-number">7.</span> <span class="toc-text">7. 双重记忆模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-%E5%85%B6%E4%BB%96%E6%B7%B7%E5%90%88%E6%96%B9%E6%B3%95"><span class="toc-number">8.</span> <span class="toc-text">8. 其他混合方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93%EF%BC%9A"><span class="toc-number">9.</span> <span class="toc-text">主要方法总结：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93%EF%BC%9A"><span class="toc-number">10.</span> <span class="toc-text">总结：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%BA%E6%96%87"><span class="toc-number"></span> <span class="toc-text">论文</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Loss-of-Plasticity-in-Continual-Deep-Reinforcement-Learning-23-03"><span class="toc-number">1.</span> <span class="toc-text">Loss of Plasticity in Continual Deep Reinforcement Learning (23&#x2F;03)</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/01/15/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E4%BA%94%E5%8D%81%E4%BA%94%EF%BC%9ATransformer2%EF%BC%9A%E8%87%AA%E9%80%82%E5%BA%94LLMs/" title="论文阅读五十五：Transformer2：自适应LLMs"><img src="/images/transformer2.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文阅读五十五：Transformer2：自适应LLMs"/></a><div class="content"><a class="title" href="/2025/01/15/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E4%BA%94%E5%8D%81%E4%BA%94%EF%BC%9ATransformer2%EF%BC%9A%E8%87%AA%E9%80%82%E5%BA%94LLMs/" title="论文阅读五十五：Transformer2：自适应LLMs">论文阅读五十五：Transformer2：自适应LLMs</a><time datetime="2025-01-15T07:54:31.000Z" title="发表于 2025-01-15 15:54:31">2025-01-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/15/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E4%BA%94%E5%8D%81%E5%9B%9B%EF%BC%9ATitans%EF%BC%9A%E5%9C%A8%E6%B5%8B%E8%AF%95%E6%97%B6%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BF%86/" title="论文阅读五十四：Titans：在测试时学习记忆"><img src="/images/titans.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文阅读五十四：Titans：在测试时学习记忆"/></a><div class="content"><a class="title" href="/2025/01/15/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E4%BA%94%E5%8D%81%E5%9B%9B%EF%BC%9ATitans%EF%BC%9A%E5%9C%A8%E6%B5%8B%E8%AF%95%E6%97%B6%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BF%86/" title="论文阅读五十四：Titans：在测试时学习记忆">论文阅读五十四：Titans：在测试时学习记忆</a><time datetime="2025-01-15T07:29:34.000Z" title="发表于 2025-01-15 15:29:34">2025-01-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/15/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E4%BA%94%E5%8D%81%E4%B8%89%EF%BC%9AGAN%E5%B7%B2%E6%AD%BB%EF%BC%9BGAN%E4%B8%87%E5%B2%81%EF%BC%81%E7%8E%B0%E4%BB%A3GAN%E5%9F%BA%E7%BA%BF/" title="论文阅读五十三：GAN已死；GAN万岁！现代GAN基线"><img src="/images/R3GAN.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文阅读五十三：GAN已死；GAN万岁！现代GAN基线"/></a><div class="content"><a class="title" href="/2025/01/15/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E4%BA%94%E5%8D%81%E4%B8%89%EF%BC%9AGAN%E5%B7%B2%E6%AD%BB%EF%BC%9BGAN%E4%B8%87%E5%B2%81%EF%BC%81%E7%8E%B0%E4%BB%A3GAN%E5%9F%BA%E7%BA%BF/" title="论文阅读五十三：GAN已死；GAN万岁！现代GAN基线">论文阅读五十三：GAN已死；GAN万岁！现代GAN基线</a><time datetime="2025-01-14T21:43:02.000Z" title="发表于 2025-01-15 05:43:02">2025-01-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/12/19/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E4%BA%94%E5%8D%81%E4%BA%8C%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83%EF%BC%9A%E7%BB%BC%E8%BF%B0/" title="论文阅读五十二：大模型的参数高效微调：综述"><img src="/images/PEFT.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文阅读五十二：大模型的参数高效微调：综述"/></a><div class="content"><a class="title" href="/2024/12/19/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E4%BA%94%E5%8D%81%E4%BA%8C%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83%EF%BC%9A%E7%BB%BC%E8%BF%B0/" title="论文阅读五十二：大模型的参数高效微调：综述">论文阅读五十二：大模型的参数高效微调：综述</a><time datetime="2024-12-19T05:36:50.000Z" title="发表于 2024-12-19 13:36:50">2024-12-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/12/17/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E4%BA%94%E5%8D%81%E4%B8%80%EF%BC%9AReFT%EF%BC%9A%E5%BC%BA%E5%8C%96%E5%BE%AE%E8%B0%83%E6%8E%A8%E7%90%86/" title="论文阅读五十一：ReFT：强化微调推理"><img src="/images/ReFT.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文阅读五十一：ReFT：强化微调推理"/></a><div class="content"><a class="title" href="/2024/12/17/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E4%BA%94%E5%8D%81%E4%B8%80%EF%BC%9AReFT%EF%BC%9A%E5%BC%BA%E5%8C%96%E5%BE%AE%E8%B0%83%E6%8E%A8%E7%90%86/" title="论文阅读五十一：ReFT：强化微调推理">论文阅读五十一：ReFT：强化微调推理</a><time datetime="2024-12-17T11:56:17.000Z" title="发表于 2024-12-17 19:56:17">2024-12-17</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By Serge Wang</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (false) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>