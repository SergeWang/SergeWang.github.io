<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>综述一：Transformer及其变体 | Model The World</title><meta name="author" content="Serge Wang"><meta name="copyright" content="Serge Wang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Transformer架构，因其自注意力机制而闻名，能够让模型根据输入序列中不同的标记之间的关系进行加权。这种机制消除了循环神经网络的需求，使得训练变得更加高效。自从2017年原始Transformer的提出以来，已经出现了多个变种，旨在优化性能、扩展其适用范围或解决一些挑战。以下是一些著名的Transformer变种，特别是那些专注于自注意力机制的： 1. 原始Transformer (Vani">
<meta property="og:type" content="article">
<meta property="og:title" content="综述一：Transformer及其变体">
<meta property="og:url" content="https://sergewang.github.io/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B8%80%EF%BC%9ATransformer%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/">
<meta property="og:site_name" content="Model The World">
<meta property="og:description" content="Transformer架构，因其自注意力机制而闻名，能够让模型根据输入序列中不同的标记之间的关系进行加权。这种机制消除了循环神经网络的需求，使得训练变得更加高效。自从2017年原始Transformer的提出以来，已经出现了多个变种，旨在优化性能、扩展其适用范围或解决一些挑战。以下是一些著名的Transformer变种，特别是那些专注于自注意力机制的： 1. 原始Transformer (Vani">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://sergewang.github.io/images/transformer.png">
<meta property="article:published_time" content="2024-11-24T11:04:52.000Z">
<meta property="article:modified_time" content="2024-11-27T08:01:17.759Z">
<meta property="article:author" content="Serge Wang">
<meta property="article:tag" content="综述">
<meta property="article:tag" content="Transformer">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://sergewang.github.io/images/transformer.png"><link rel="shortcut icon" href="/img/newlogo.png"><link rel="canonical" href="https://sergewang.github.io/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B8%80%EF%BC%9ATransformer%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="IDUolVgWkW_cmu1mtW5hsxrrIjQfCHvq5hOTOkXeVNE"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        if (name && globalFn[key][name]) return
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?9dcb7eb7a8a6225c2b1f242f3b0894bf";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
btf.addGlobalFn('pjaxComplete', () => {
  _hmt.push(['_trackPageview',window.location.pathname])
}, 'baidu_analytics')
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-XERFYF0N5K"></script><script>window.dataLayer = window.dataLayer || []
function gtag(){dataLayer.push(arguments)}
gtag('js', new Date())
gtag('config', 'G-XERFYF0N5K')
btf.addGlobalFn('pjaxComplete', () => {
  gtag('config', 'G-XERFYF0N5K', {'page_path': window.location.pathname})
}, 'google_analytics')
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '综述一：Transformer及其变体',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-11-27 16:01:17'
}</script></head><body><div id="web_bg" style="background-image: url(/img/background.png);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/newlogo.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">65</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">39</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">17</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/images/transformer.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="/img/newlogo.png" alt="Logo"><span class="site-name">Model The World</span></a><a class="nav-page-title" href="/"><span class="site-name">综述一：Transformer及其变体</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">综述一：Transformer及其变体</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-11-24T11:04:52.000Z" title="发表于 2024-11-24 19:04:52">2024-11-24</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-11-27T08:01:17.759Z" title="更新于 2024-11-27 16:01:17">2024-11-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Transformer/">Transformer</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>Transformer架构，因其自注意力机制而闻名，能够让模型根据输入序列中不同的标记之间的关系进行加权。这种机制消除了循环神经网络的需求，使得训练变得更加高效。自从2017年原始Transformer的提出以来，已经出现了多个变种，旨在优化性能、扩展其适用范围或解决一些挑战。以下是一些著名的Transformer变种，特别是那些专注于自注意力机制的：</p>
<h3 id="1-原始Transformer-Vanilla-Transformer">1. <strong>原始Transformer (Vanilla Transformer)</strong></h3>
<ul>
<li><strong>关键特性</strong>：原始Transformer架构包括一个编码器-解码器结构，采用自注意力机制。</li>
<li><strong>目的</strong>：消除了递归神经网络的需求，使得模型训练更加并行化和高效。</li>
<li><strong>自注意力机制</strong>：多头自注意力，通过计算输入序列中所有标记之间的关系来决定重要性。</li>
</ul>
<h3 id="2-BERT（双向编码器表示）">2. <strong>BERT（双向编码器表示）</strong></h3>
<ul>
<li><strong>关键特性</strong>：BERT只使用Transformer的编码器部分，采用双向自注意力机制来捕获标记的左右上下文。</li>
<li><strong>目的</strong>：通过掩蔽语言模型（MLM）进行预训练，并可以通过微调来提升在下游NLP任务中的表现。</li>
</ul>
<h3 id="3-GPT（生成式预训练Transformer）">3. <strong>GPT（生成式预训练Transformer）</strong></h3>
<ul>
<li><strong>关键特性</strong>：GPT使用单向（因果）自注意力机制，每个标记只能注意到其前面的标记。</li>
<li><strong>目的</strong>：作为自回归模型，主要用于文本生成任务，即根据前面的标记预测下一个标记。</li>
</ul>
<h3 id="4-T5（文本到文本的传输Transformer）">4. <strong>T5（文本到文本的传输Transformer）</strong></h3>
<ul>
<li><strong>关键特性</strong>：T5将每个NLP任务都转化为文本到文本的问题，输入和输出都以文本格式表示。</li>
<li><strong>目的</strong>：使用统一的框架处理多种任务，如翻译、摘要和问答。</li>
</ul>
<h3 id="5-Transformer-XL（扩展长序列Transformer）">5. <strong>Transformer-XL（扩展长序列Transformer）</strong></h3>
<ul>
<li><strong>关键特性</strong>：Transformer-XL引入了递归机制和基于段落的递归方法，使得模型能够处理更长的序列，并建模长期依赖关系。</li>
<li><strong>目的</strong>：通过扩展上下文来改进长距离依赖的处理能力。</li>
</ul>
<h3 id="6-XLNet">6. <strong>XLNet</strong></h3>
<ul>
<li><strong>关键特性</strong>：XLNet扩展了Transformer-XL，通过使用排列训练目标，既能捕获双向上下文（像BERT），又能保持自回归特性（像GPT）。</li>
<li><strong>目的</strong>：结合BERT和GPT的优点，在生成式和理解式任务中都能表现出色。</li>
</ul>
<h3 id="7-RoBERTa（鲁棒优化的BERT）">7. <strong>RoBERTa（鲁棒优化的BERT）</strong></h3>
<ul>
<li><strong>关键特性</strong>：RoBERTa是BERT的变种，通过使用更多的数据、更长的训练时间，并移除下一个句子预测任务来改进BERT。</li>
<li><strong>目的</strong>：优化BERT的预训练过程，提升下游任务的表现。</li>
</ul>
<h3 id="8-ALBERT（轻量化BERT）">8. <strong>ALBERT（轻量化BERT）</strong></h3>
<ul>
<li><strong>关键特性</strong>：ALBERT通过在层间共享权重和因式分解嵌入矩阵来减少模型的大小和复杂性。</li>
<li><strong>目的</strong>：在保持性能的同时，减少计算资源的消耗和模型大小。</li>
</ul>
<h3 id="9-DistilBERT">9. <strong>DistilBERT</strong></h3>
<ul>
<li><strong>关键特性</strong>：DistilBERT是通过知识蒸馏（Knowledge Distillation）生成的BERT的一个小版本，保留了97%的BERT语言理解能力，但参数更少。</li>
<li><strong>目的</strong>：为资源受限的环境创建一个更小、更快速的BERT版本。</li>
</ul>
<h3 id="10-Longformer">10. <strong>Longformer</strong></h3>
<ul>
<li><strong>关键特性</strong>：Longformer引入了稀疏自注意力机制，每个标记仅关注一个有限的局部窗口，而不是与所有其他标记进行计算。</li>
<li><strong>目的</strong>：专门设计用于高效处理长文档，通过减少自注意力的二次复杂度，降低计算量。</li>
</ul>
<h3 id="11-Linformer">11. <strong>Linformer</strong></h3>
<ul>
<li><strong>关键特性</strong>：Linformer通过低秩矩阵分解来近似自注意力机制，将注意力操作的复杂度从(O(n^2))降低到(O(n))。</li>
<li><strong>目的</strong>：使自注意力机制能够扩展到长序列上。</li>
</ul>
<h3 id="12-Reformer">12. <strong>Reformer</strong></h3>
<ul>
<li><strong>关键特性</strong>：Reformer使用局部敏感哈希（LSH）来减少注意力的复杂性，并使用可逆层来减少内存使用。</li>
<li><strong>目的</strong>：为长序列的处理提供更高效的内存使用，并优化计算效率。</li>
</ul>
<h3 id="13-ELECTRA">13. <strong>ELECTRA</strong></h3>
<ul>
<li><strong>关键特性</strong>：ELECTRA通过生成器和鉴别器来替换预训练中的掩蔽标记。鉴别器预测一个标记是真实的还是被替换的。</li>
<li><strong>目的</strong>：比BERT更加样本高效，可以使用更少的训练资源获得更好的性能。</li>
</ul>
<h3 id="14-DeBERTa（解码增强BERT与解耦注意力）">14. <strong>DeBERTa（解码增强BERT与解耦注意力）</strong></h3>
<ul>
<li><strong>关键特性</strong>：DeBERTa引入了解耦注意力，能够更好地建模位置和相对标记之间的交互。</li>
<li><strong>目的</strong>：通过增强标记之间的依赖关系建模，改进BERT和RoBERTa的性能。</li>
</ul>
<h3 id="15-Swin-Transformer（平移窗口Transformer）">15. <strong>Swin Transformer（平移窗口Transformer）</strong></h3>
<ul>
<li><strong>关键特性</strong>：这是专门为视觉任务设计的Transformer架构，在局部窗口内应用自注意力机制，在层间通过平移窗口捕获全局上下文。</li>
<li><strong>目的</strong>：用于计算机视觉任务，如图像分类，通过分层结构实现高效的图像处理。</li>
</ul>
<h3 id="16-Vision-Transformer（ViT）">16. <strong>Vision Transformer（ViT）</strong></h3>
<ul>
<li><strong>关键特性</strong>：将标准Transformer架构应用于视觉任务，将图像划分为多个小块，将这些小块视为输入序列的标记。</li>
<li><strong>目的</strong>：通过不使用卷积神经网络（CNN）进行图像分类等视觉任务，探索图像处理的新方法。</li>
</ul>
<h3 id="17-Performer">17. <strong>Performer</strong></h3>
<ul>
<li><strong>关键特性</strong>：Performer通过基于核方法的近似来替换传统的自注意力机制，从而提高了计算效率。</li>
<li><strong>目的</strong>：通过近似核方法提高注意力机制的效率，优化计算资源的消耗。</li>
</ul>
<h3 id="18-LaMDA（对话应用的语言模型）">18. <strong>LaMDA（对话应用的语言模型）</strong></h3>
<ul>
<li><strong>关键特性</strong>：由Google设计，LaMDA是一个对话型AI模型，采用针对对话任务优化的Transformer架构。</li>
<li><strong>目的</strong>：生成更加自然和开放式的对话。</li>
</ul>
<h3 id="19-BigBird">19. <strong>BigBird</strong></h3>
<ul>
<li><strong>关键特性</strong>：BigBird是另一个用于长文档的变种，通过组合全局、局部和随机注意力模式来减少计算复杂度。</li>
<li><strong>目的</strong>：高效处理长文档，在内存和计算效率上超越早期的模型。</li>
</ul>
<h3 id="20-稀疏Transformer">20. <strong>稀疏Transformer</strong></h3>
<ul>
<li><strong>关键特性</strong>：稀疏Transformer通过限制标记之间的交互来减少自注意力的计算成本。</li>
<li><strong>目的</strong>：通过使用稀疏注意力模式来高效处理长序列。</li>
</ul>
<h3 id="21-Mistral">21. <strong>Mistral</strong></h3>
<ul>
<li><strong>关键特性</strong>：Mistral是一种高效的密集Transformer模型，设计时考虑了稀疏性和计算效率，旨在比GPT和BERT更轻量。</li>
<li><strong>目的</strong>：在性能和计算效率之间找到平衡，构建更加紧凑的模型。</li>
</ul>
<h3 id="22-Funnel-Transformer">22. <strong>Funnel Transformer</strong></h3>
<ul>
<li><strong>关键特性</strong>：Funnel Transformer使用渐进式降采样机制，将序列长度在层级中逐渐减少，专注于更相关的信息。</li>
<li><strong>目的</strong>：通过逐渐缩减输入序列，在减少计算成本的同时高效地处理长序列。</li>
</ul>
<hr>
<p>这些变种展示了Transformer架构随着时间发展而做出的多种适应和改进，涉及到计算效率、内存使用、长序列处理、以及特定任务的优化等不同方面。其中一些变种专注于提高处理长序列的能力（例如Longformer、Linformer、Reformer），而其他一些则优化了处理特定任务的能力（例如Vision Transformer用于图像，T5用于多任务NLP）。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://SergeWang.github.io">Serge Wang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://sergewang.github.io/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B8%80%EF%BC%9ATransformer%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/">https://sergewang.github.io/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B8%80%EF%BC%9ATransformer%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://SergeWang.github.io" target="_blank">Model The World</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%BB%BC%E8%BF%B0/">综述</a><a class="post-meta__tags" href="/tags/Transformer/">Transformer</a></div><div class="post-share"><div class="social-share" data-image="/images/transformer.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2024/11/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E4%B8%89%E5%8D%81%E4%B9%9D%EF%BC%9ASAMURAI%EF%BC%9A%E7%94%A8%E4%BA%8E%E9%9B%B6%E6%A0%B7%E6%9C%AC%E8%A7%86%E8%A7%89%E8%BF%BD%E8%B8%AA%E7%9A%84%E5%85%B7%E6%9C%89%E8%BF%90%E5%8A%A8%E6%84%9F%E7%9F%A5%E8%AE%B0%E5%BF%86%E7%9A%84%E8%87%AA%E9%80%82%E5%BA%94SAM/" title="论文阅读三十九：SAMURAI：用于零样本视觉追踪的具有运动感知记忆的自适应SAM"><img class="cover" src="/images/SAMRUAI.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">论文阅读三十九：SAMURAI：用于零样本视觉追踪的具有运动感知记忆的自适应SAM</div></div><div class="info-2"><div class="info-item-1">摘要 分割一切模型 2（SAM2）在目标分割任务上已经展示强大性能，但在视觉目标追踪中面临挑战，尤其当处理具有快速移动或自遮挡的物体的拥挤场景时。此外，原始模型中固定窗口的记忆方法未考虑选择用于下一帧调节的图像特征的记忆的质量，导致视频中的误差传播。本文介绍SAMURAI，SAM2的增强适应性版，专为视觉目标跟踪而设计。通过结合时间运动线索和提出的运动感知记忆选择机制，SAMURAI有效地预测目标运动，并优化掩码选择，无需再训练或微调，取得稳健精确追踪。SAMURAI实时操作，并在各种基准数据集上展示强大的零样本性能，说明了它的无需微调的泛化能力。评估中，SAMURAI在现有追踪器的成功率和精度上取得显著改进， LaSOTextLaSOT_{ext}LaSOText​上增益为 7.1%， GOT-10k上增益3.5%。而且，它相较于LaSOT上的全监督方法取得竞争性的结果，突出了它在复杂追踪场景的健壮性，以及它在真实世界动态环境应用上的潜力。代码和结果在： https://github.com/yangchris11/samurai...</div></div></div></a><a class="pagination-related" href="/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B8%83%EF%BC%9ACNN%E6%A8%A1%E5%9E%8B/" title="综述七：CNN模型"><img class="cover" src="/images/mamba.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">综述七：CNN模型</div></div><div class="info-2"><div class="info-item-1">Here’s a list of major CNN (Convolutional Neural Network) variants ordered by the time of their publication. CNNs have evolved over the years to improve accuracy, reduce computational costs, and adapt to different domains.  1. LeNet (1998)  Key Idea: One of the first CNN architectures, designed for handwritten digit recognition (MNIST). It used convolutional layers followed by pooling and fully connected layers. Application: Digit classification. Notable Paper: Yann LeCun et al.,...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B8%83%EF%BC%9ACNN%E6%A8%A1%E5%9E%8B/" title="综述七：CNN模型"><img class="cover" src="/images/mamba.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-24</div><div class="info-item-2">综述七：CNN模型</div></div><div class="info-2"><div class="info-item-1">Here’s a list of major CNN (Convolutional Neural Network) variants ordered by the time of their publication. CNNs have evolved over the years to improve accuracy, reduce computational costs, and adapt to different domains.  1. LeNet (1998)  Key Idea: One of the first CNN architectures, designed for handwritten digit recognition (MNIST). It used convolutional layers followed by pooling and fully connected layers. Application: Digit classification. Notable Paper: Yann LeCun et al.,...</div></div></div></a><a class="pagination-related" href="/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B8%89%EF%BC%9A%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0%E5%8F%8A%E5%85%B6%E6%96%B9%E6%B3%95/" title="综述三：持续学习及其方法"><img class="cover" src="/images/mamba.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-24</div><div class="info-item-2">综述三：持续学习及其方法</div></div><div class="info-2"><div class="info-item-1">持续学习（Continual Learning，CL），也称为终身学习（Lifelong Learning），指的是模型能够从持续不断的数据流中学习，并随着时间的推移不断适应和获得新知识，而不会遗忘先前学习的内容。持续学习面临的一个主要挑战是灾难性遗忘（Catastrophic Forgetting），即在学习新任务时，模型容易遗忘之前学习的任务。 为了应对这些挑战，提出了多种方法，这些方法可以根据它们如何处理遗忘、如何存储知识以及如何使用新数据进行分类。 下面是主要的持续学习方法，按它们所采用的主要策略进行组织： 1....</div></div></div></a><a class="pagination-related" href="/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%BA%8C%EF%BC%9ADiTs%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/" title="综述二：DiTs及其变体"><img class="cover" src="/images/SIT.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-24</div><div class="info-item-2">综述二：DiTs及其变体</div></div><div class="info-2"><div class="info-item-1">**DiT（去噪扩散Transformer模型）**是结合了Transformer架构和扩散模型的一类生成模型，特别专注于在扩散框架内的去噪过程。扩散模型通过逐步添加和去除噪声的过程来建模复杂的分布，近年来在生成任务中非常流行。 下面是一些著名的DiT变种，它们在不同方面扩展了原始的DiT模型： 1. DiT（原始版本）  关键特性：原始的DiT模型将Transformer架构与去噪扩散过程结合，利用Transformer的注意力机制改进生成质量和训练的可扩展性。 目的：生成高质量的图像，并与传统的卷积神经网络相比，提高训练效率。  2. DiT++（增强版DiT）  关键特性：DiT++是在原始DiT基础上进行增强的版本，可能包括模型架构的改进、训练方法的优化或额外的正则化技术。 目的：通过改进Transformer架构和扩散过程中的噪声调度，提升生成稳定性和性能。  3....</div></div></div></a><a class="pagination-related" href="/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%BA%94%EF%BC%9A%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%8F%8A%E5%85%B6%E5%88%86%E7%B1%BB/" title="综述五：强化学习及其分类"><img class="cover" src="/images/mamba.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-24</div><div class="info-item-2">综述五：强化学习及其分类</div></div><div class="info-2"><div class="info-item-1">强化学习的变种 强化学习（Reinforcement Learning，简称RL）是一种机器学习方法，其中代理（Agent）通过与环境的交互来学习做出决策。代理的目标是通过采取适当的行动，最大化长期累积的奖励。强化学习是一个广泛的领域，许多不同的变种和算法已被开发出来，以解决学习、探索和决策等不同方面的问题。 以下是强化学习的主要变种及其子类别：  1. 无模型 vs 有模型强化学习  无模型强化学习（Model-Free RL）：代理不构建或使用环境的动态模型，而是直接通过与环境的交互来学习。  示例：  Q学习（Q-Learning，包括表格化和深度Q学习） 策略梯度方法（例如，REINFORCE） Actor-Critic方法（例如A3C，PPO）     有模型强化学习（Model-Based RL）：代理试图学习环境的转移动态和奖励函数，并利用这些模型来做出更有信息量的决策。  示例：  Dyna-Q（Q学习与规划结合） World Models 蒙特卡洛树搜索（MCTS）       2....</div></div></div></a><a class="pagination-related" href="/2024/11/24/%E7%BB%BC%E8%BF%B0%E5%85%AB%EF%BC%9A%E9%AB%98%E6%96%AF%E6%B3%BC%E6%BA%85/" title="综述八：高斯泼溅"><img class="cover" src="/images/mamba.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-24</div><div class="info-item-2">综述八：高斯泼溅</div></div><div class="info-2"><div class="info-item-1">模型 3d gaussian splatting for real-time radiance field rendering （23/08） 论文阅读三十一：3D高斯溅射用于实时辐射场渲染 贡献：  引入各向异性（anisotropic）3D高斯作为高质量、非结构化的辐射场表示。 3D高斯属性的优化方法，与自适应密度控制交织，为捕获的场景创建高质量的表示。 快速可微GPU渲染方法，具有可见性感知，允许各向异性泼溅和快速后向传播，从而获得高质量的新视图合成。     </div></div></div></a><a class="pagination-related" href="/2024/11/24/%E7%BB%BC%E8%BF%B0%E5%85%AD%EF%BC%9A%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96%E6%8A%80%E6%9C%AF/" title="综述六：模型量化技术"><img class="cover" src="/images/mamba.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-24</div><div class="info-item-2">综述六：模型量化技术</div></div><div class="info-2"><div class="info-item-1">量化技术在机器学习（ML）和大型语言模型（LLM）中的应用，指的是将模型的权重和激活值的数值精度降低，通常目的是提高计算效率、减少内存占用，并加速推理过程，而不显著降低准确度。随着时间的推移，这些方法在传统机器学习和深度学习的研究中不断发展。 以下是按引入时间排序的 量化方法 列表：  1. 定点量化（Fixed-Point Quantization） (1980年代 - 1990年代初)  核心思想：将浮点数（32位）转换为定点数（例如16位或8位整数）。这可以减少内存需求，并加速计算，因为定点操作通常比浮点操作在硬件上更高效。 应用：早期的信号处理和硬件实现。   2. 向量量化（Vector Quantization）(1980年代 - 1990年代)  核心思想：通过使用较少的质心或码本来表示高维向量（如特征表示）。这是一种有损压缩技术，用于减少表示的维度。 应用：用于图像和语音压缩。 重要论文：Gray, “Vector Quantization and Signal Compression”, 1984。   3. 产品量化（Product...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/newlogo.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Serge Wang</div><div class="author-info-description">今日事，今日毕</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">65</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">39</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">17</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/SergeWang"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/SergeWang" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:sergew027@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">Welcome to my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%8E%9F%E5%A7%8BTransformer-Vanilla-Transformer"><span class="toc-number">1.</span> <span class="toc-text">1. 原始Transformer (Vanilla Transformer)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-BERT%EF%BC%88%E5%8F%8C%E5%90%91%E7%BC%96%E7%A0%81%E5%99%A8%E8%A1%A8%E7%A4%BA%EF%BC%89"><span class="toc-number">2.</span> <span class="toc-text">2. BERT（双向编码器表示）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-GPT%EF%BC%88%E7%94%9F%E6%88%90%E5%BC%8F%E9%A2%84%E8%AE%AD%E7%BB%83Transformer%EF%BC%89"><span class="toc-number">3.</span> <span class="toc-text">3. GPT（生成式预训练Transformer）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-T5%EF%BC%88%E6%96%87%E6%9C%AC%E5%88%B0%E6%96%87%E6%9C%AC%E7%9A%84%E4%BC%A0%E8%BE%93Transformer%EF%BC%89"><span class="toc-number">4.</span> <span class="toc-text">4. T5（文本到文本的传输Transformer）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-Transformer-XL%EF%BC%88%E6%89%A9%E5%B1%95%E9%95%BF%E5%BA%8F%E5%88%97Transformer%EF%BC%89"><span class="toc-number">5.</span> <span class="toc-text">5. Transformer-XL（扩展长序列Transformer）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-XLNet"><span class="toc-number">6.</span> <span class="toc-text">6. XLNet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-RoBERTa%EF%BC%88%E9%B2%81%E6%A3%92%E4%BC%98%E5%8C%96%E7%9A%84BERT%EF%BC%89"><span class="toc-number">7.</span> <span class="toc-text">7. RoBERTa（鲁棒优化的BERT）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-ALBERT%EF%BC%88%E8%BD%BB%E9%87%8F%E5%8C%96BERT%EF%BC%89"><span class="toc-number">8.</span> <span class="toc-text">8. ALBERT（轻量化BERT）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-DistilBERT"><span class="toc-number">9.</span> <span class="toc-text">9. DistilBERT</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-Longformer"><span class="toc-number">10.</span> <span class="toc-text">10. Longformer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-Linformer"><span class="toc-number">11.</span> <span class="toc-text">11. Linformer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-Reformer"><span class="toc-number">12.</span> <span class="toc-text">12. Reformer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-ELECTRA"><span class="toc-number">13.</span> <span class="toc-text">13. ELECTRA</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#14-DeBERTa%EF%BC%88%E8%A7%A3%E7%A0%81%E5%A2%9E%E5%BC%BABERT%E4%B8%8E%E8%A7%A3%E8%80%A6%E6%B3%A8%E6%84%8F%E5%8A%9B%EF%BC%89"><span class="toc-number">14.</span> <span class="toc-text">14. DeBERTa（解码增强BERT与解耦注意力）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#15-Swin-Transformer%EF%BC%88%E5%B9%B3%E7%A7%BB%E7%AA%97%E5%8F%A3Transformer%EF%BC%89"><span class="toc-number">15.</span> <span class="toc-text">15. Swin Transformer（平移窗口Transformer）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#16-Vision-Transformer%EF%BC%88ViT%EF%BC%89"><span class="toc-number">16.</span> <span class="toc-text">16. Vision Transformer（ViT）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-Performer"><span class="toc-number">17.</span> <span class="toc-text">17. Performer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#18-LaMDA%EF%BC%88%E5%AF%B9%E8%AF%9D%E5%BA%94%E7%94%A8%E7%9A%84%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%89"><span class="toc-number">18.</span> <span class="toc-text">18. LaMDA（对话应用的语言模型）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#19-BigBird"><span class="toc-number">19.</span> <span class="toc-text">19. BigBird</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#20-%E7%A8%80%E7%96%8FTransformer"><span class="toc-number">20.</span> <span class="toc-text">20. 稀疏Transformer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#21-Mistral"><span class="toc-number">21.</span> <span class="toc-text">21. Mistral</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-Funnel-Transformer"><span class="toc-number">22.</span> <span class="toc-text">22. Funnel Transformer</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/11/27/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9B%9B%E5%8D%81%E5%9B%9B%EF%BC%9A%E7%94%A8%E4%BA%8E%E9%AB%98%E6%95%88%E7%BB%86%E8%87%B4%E8%A1%A8%E9%9D%A2%E9%87%8D%E5%BB%BA%E7%9A%84%E4%BA%8C%E6%AC%A1%E9%AB%98%E6%96%AF%E6%B3%BC%E6%BA%85/" title="论文阅读四十四：用于高效细致表面重建的二次高斯泼溅"><img src="/images/QGS.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文阅读四十四：用于高效细致表面重建的二次高斯泼溅"/></a><div class="content"><a class="title" href="/2024/11/27/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9B%9B%E5%8D%81%E5%9B%9B%EF%BC%9A%E7%94%A8%E4%BA%8E%E9%AB%98%E6%95%88%E7%BB%86%E8%87%B4%E8%A1%A8%E9%9D%A2%E9%87%8D%E5%BB%BA%E7%9A%84%E4%BA%8C%E6%AC%A1%E9%AB%98%E6%96%AF%E6%B3%BC%E6%BA%85/" title="论文阅读四十四：用于高效细致表面重建的二次高斯泼溅">论文阅读四十四：用于高效细致表面重建的二次高斯泼溅</a><time datetime="2024-11-27T02:15:57.000Z" title="发表于 2024-11-27 10:15:57">2024-11-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/11/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9B%9B%E5%8D%81%E4%B8%89%EF%BC%9A%E6%B5%8B%E8%AF%95%E6%97%B6%E9%AB%98%E6%95%88%E5%AD%A6%E4%B9%A0%EF%BC%9ALLMs%E7%9A%84%E4%B8%BB%E5%8A%A8%E5%BE%AE%E8%B0%83/" title="论文阅读四十三：测试时高效学习：LLMs的主动微调"><img src="/images/SIFT.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文阅读四十三：测试时高效学习：LLMs的主动微调"/></a><div class="content"><a class="title" href="/2024/11/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9B%9B%E5%8D%81%E4%B8%89%EF%BC%9A%E6%B5%8B%E8%AF%95%E6%97%B6%E9%AB%98%E6%95%88%E5%AD%A6%E4%B9%A0%EF%BC%9ALLMs%E7%9A%84%E4%B8%BB%E5%8A%A8%E5%BE%AE%E8%B0%83/" title="论文阅读四十三：测试时高效学习：LLMs的主动微调">论文阅读四十三：测试时高效学习：LLMs的主动微调</a><time datetime="2024-11-26T13:05:57.000Z" title="发表于 2024-11-26 21:05:57">2024-11-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/11/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9B%9B%E5%8D%81%E4%BA%8C%EF%BC%9A1%E4%BD%8DAI%E6%9E%B6%E6%9E%84%EF%BC%9A%E9%83%A8%E5%88%861-1%EF%BC%8C%E5%9F%BA%E4%BA%8EGPU%E7%9A%84%E5%BF%AB%E9%80%9F%E6%97%A0%E6%8D%9FBitNet-b1-58%E6%8E%A8%E7%90%86/" title="论文阅读四十二：1位AI架构：部分1.1，基于GPU的快速无损BitNet b1.58推理"><img src="/images/bitnet.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文阅读四十二：1位AI架构：部分1.1，基于GPU的快速无损BitNet b1.58推理"/></a><div class="content"><a class="title" href="/2024/11/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9B%9B%E5%8D%81%E4%BA%8C%EF%BC%9A1%E4%BD%8DAI%E6%9E%B6%E6%9E%84%EF%BC%9A%E9%83%A8%E5%88%861-1%EF%BC%8C%E5%9F%BA%E4%BA%8EGPU%E7%9A%84%E5%BF%AB%E9%80%9F%E6%97%A0%E6%8D%9FBitNet-b1-58%E6%8E%A8%E7%90%86/" title="论文阅读四十二：1位AI架构：部分1.1，基于GPU的快速无损BitNet b1.58推理">论文阅读四十二：1位AI架构：部分1.1，基于GPU的快速无损BitNet b1.58推理</a><time datetime="2024-11-26T10:57:57.000Z" title="发表于 2024-11-26 18:57:57">2024-11-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/11/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9B%9B%E5%8D%81%E4%B8%80%EF%BC%9ATransformer%E4%B8%AD%E9%87%8D%E8%A6%81%E7%9A%84%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E5%B9%B6%E9%9D%9E%E6%89%80%E6%9C%89%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E9%83%BD%E9%9C%80%E8%A6%81/" title="论文阅读四十一：Transformer中重要的是什么？并非所有的注意力都需要"><img src="/images/llm-drop.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文阅读四十一：Transformer中重要的是什么？并非所有的注意力都需要"/></a><div class="content"><a class="title" href="/2024/11/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9B%9B%E5%8D%81%E4%B8%80%EF%BC%9ATransformer%E4%B8%AD%E9%87%8D%E8%A6%81%E7%9A%84%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E5%B9%B6%E9%9D%9E%E6%89%80%E6%9C%89%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E9%83%BD%E9%9C%80%E8%A6%81/" title="论文阅读四十一：Transformer中重要的是什么？并非所有的注意力都需要">论文阅读四十一：Transformer中重要的是什么？并非所有的注意力都需要</a><time datetime="2024-11-26T10:55:38.000Z" title="发表于 2024-11-26 18:55:38">2024-11-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/11/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9B%9B%E5%8D%81%EF%BC%9A%E5%A4%A7%E5%9E%8B%E8%A7%86%E8%A7%89%E7%BC%96%E7%A0%81%E5%99%A8%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E8%87%AA%E5%9B%9E%E5%BD%92%E9%A2%84%E8%AE%AD%E7%BB%83/" title="论文阅读四十：大型视觉编码器的多模态自回归预训练"><img src="/images/AIMv2.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文阅读四十：大型视觉编码器的多模态自回归预训练"/></a><div class="content"><a class="title" href="/2024/11/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9B%9B%E5%8D%81%EF%BC%9A%E5%A4%A7%E5%9E%8B%E8%A7%86%E8%A7%89%E7%BC%96%E7%A0%81%E5%99%A8%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E8%87%AA%E5%9B%9E%E5%BD%92%E9%A2%84%E8%AE%AD%E7%BB%83/" title="论文阅读四十：大型视觉编码器的多模态自回归预训练">论文阅读四十：大型视觉编码器的多模态自回归预训练</a><time datetime="2024-11-26T10:52:16.000Z" title="发表于 2024-11-26 18:52:16">2024-11-26</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2024 By Serge Wang</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (false) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>