<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>综述一：Transformer及其变体 | Model The World</title><meta name="author" content="Serge Wang"><meta name="copyright" content="Serge Wang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Transformer架构，因其自注意力机制而闻名，能够让模型根据输入序列中不同的标记之间的关系进行加权。这种机制消除了循环神经网络的需求，使得训练变得更加高效。自从2017年原始Transformer的提出以来，已经出现了多个变种，旨在优化性能、扩展其适用范围或解决一些挑战。以下是一些著名的Transformer变种，特别是那些专注于自注意力机制的： 1. 原始Transformer (Vani">
<meta property="og:type" content="article">
<meta property="og:title" content="综述一：Transformer及其变体">
<meta property="og:url" content="https://sergewang.github.io/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B8%80%EF%BC%9ATransformer%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/">
<meta property="og:site_name" content="Model The World">
<meta property="og:description" content="Transformer架构，因其自注意力机制而闻名，能够让模型根据输入序列中不同的标记之间的关系进行加权。这种机制消除了循环神经网络的需求，使得训练变得更加高效。自从2017年原始Transformer的提出以来，已经出现了多个变种，旨在优化性能、扩展其适用范围或解决一些挑战。以下是一些著名的Transformer变种，特别是那些专注于自注意力机制的： 1. 原始Transformer (Vani">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://sergewang.github.io/images/transformer.png">
<meta property="article:published_time" content="2024-11-24T11:04:52.000Z">
<meta property="article:modified_time" content="2024-12-04T09:15:27.976Z">
<meta property="article:author" content="Serge Wang">
<meta property="article:tag" content="综述">
<meta property="article:tag" content="Transformer">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://sergewang.github.io/images/transformer.png"><link rel="shortcut icon" href="/img/newlogo.png"><link rel="canonical" href="https://sergewang.github.io/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B8%80%EF%BC%9ATransformer%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="IDUolVgWkW_cmu1mtW5hsxrrIjQfCHvq5hOTOkXeVNE"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        if (name && globalFn[key][name]) return
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?9dcb7eb7a8a6225c2b1f242f3b0894bf";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
btf.addGlobalFn('pjaxComplete', () => {
  _hmt.push(['_trackPageview',window.location.pathname])
}, 'baidu_analytics')
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-XERFYF0N5K"></script><script>window.dataLayer = window.dataLayer || []
function gtag(){dataLayer.push(arguments)}
gtag('js', new Date())
gtag('config', 'G-XERFYF0N5K')
btf.addGlobalFn('pjaxComplete', () => {
  gtag('config', 'G-XERFYF0N5K', {'page_path': window.location.pathname})
}, 'google_analytics')
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '综述一：Transformer及其变体',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-12-04 17:15:27'
}</script></head><body><div id="web_bg" style="background-image: url(/img/background.png);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/newlogo.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">74</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">43</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">20</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/images/transformer.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="/img/newlogo.png" alt="Logo"><span class="site-name">Model The World</span></a><a class="nav-page-title" href="/"><span class="site-name">综述一：Transformer及其变体</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">综述一：Transformer及其变体</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-11-24T11:04:52.000Z" title="发表于 2024-11-24 19:04:52">2024-11-24</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-12-04T09:15:27.976Z" title="更新于 2024-12-04 17:15:27">2024-12-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Transformer/">Transformer</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>Transformer架构，因其自注意力机制而闻名，能够让模型根据输入序列中不同的标记之间的关系进行加权。这种机制消除了循环神经网络的需求，使得训练变得更加高效。自从2017年原始Transformer的提出以来，已经出现了多个变种，旨在优化性能、扩展其适用范围或解决一些挑战。以下是一些著名的Transformer变种，特别是那些专注于自注意力机制的：</p>
<h3 id="1-原始Transformer-Vanilla-Transformer">1. <strong>原始Transformer (Vanilla Transformer)</strong></h3>
<ul>
<li><strong>关键特性</strong>：原始Transformer架构包括一个编码器-解码器结构，采用自注意力机制。</li>
<li><strong>目的</strong>：消除了递归神经网络的需求，使得模型训练更加并行化和高效。</li>
<li><strong>自注意力机制</strong>：多头自注意力，通过计算输入序列中所有标记之间的关系来决定重要性。</li>
</ul>
<h3 id="2-BERT（双向编码器表示）">2. <strong>BERT（双向编码器表示）</strong></h3>
<ul>
<li><strong>关键特性</strong>：BERT只使用Transformer的编码器部分，采用双向自注意力机制来捕获标记的左右上下文。</li>
<li><strong>目的</strong>：通过掩蔽语言模型（MLM）进行预训练，并可以通过微调来提升在下游NLP任务中的表现。</li>
</ul>
<h3 id="3-GPT（生成式预训练Transformer）">3. <strong>GPT（生成式预训练Transformer）</strong></h3>
<ul>
<li><strong>关键特性</strong>：GPT使用单向（因果）自注意力机制，每个标记只能注意到其前面的标记。</li>
<li><strong>目的</strong>：作为自回归模型，主要用于文本生成任务，即根据前面的标记预测下一个标记。</li>
</ul>
<h3 id="4-T5（文本到文本的传输Transformer）">4. <strong>T5（文本到文本的传输Transformer）</strong></h3>
<ul>
<li><strong>关键特性</strong>：T5将每个NLP任务都转化为文本到文本的问题，输入和输出都以文本格式表示。</li>
<li><strong>目的</strong>：使用统一的框架处理多种任务，如翻译、摘要和问答。</li>
</ul>
<h3 id="5-Transformer-XL（扩展长序列Transformer）">5. <strong>Transformer-XL（扩展长序列Transformer）</strong></h3>
<ul>
<li><strong>关键特性</strong>：Transformer-XL引入了递归机制和基于段落的递归方法，使得模型能够处理更长的序列，并建模长期依赖关系。</li>
<li><strong>目的</strong>：通过扩展上下文来改进长距离依赖的处理能力。</li>
</ul>
<h3 id="6-XLNet">6. <strong>XLNet</strong></h3>
<ul>
<li><strong>关键特性</strong>：XLNet扩展了Transformer-XL，通过使用排列训练目标，既能捕获双向上下文（像BERT），又能保持自回归特性（像GPT）。</li>
<li><strong>目的</strong>：结合BERT和GPT的优点，在生成式和理解式任务中都能表现出色。</li>
</ul>
<h3 id="7-RoBERTa（鲁棒优化的BERT）">7. <strong>RoBERTa（鲁棒优化的BERT）</strong></h3>
<ul>
<li><strong>关键特性</strong>：RoBERTa是BERT的变种，通过使用更多的数据、更长的训练时间，并移除下一个句子预测任务来改进BERT。</li>
<li><strong>目的</strong>：优化BERT的预训练过程，提升下游任务的表现。</li>
</ul>
<h3 id="8-ALBERT（轻量化BERT）">8. <strong>ALBERT（轻量化BERT）</strong></h3>
<ul>
<li><strong>关键特性</strong>：ALBERT通过在层间共享权重和因式分解嵌入矩阵来减少模型的大小和复杂性。</li>
<li><strong>目的</strong>：在保持性能的同时，减少计算资源的消耗和模型大小。</li>
</ul>
<h3 id="9-DistilBERT">9. <strong>DistilBERT</strong></h3>
<ul>
<li><strong>关键特性</strong>：DistilBERT是通过知识蒸馏（Knowledge Distillation）生成的BERT的一个小版本，保留了97%的BERT语言理解能力，但参数更少。</li>
<li><strong>目的</strong>：为资源受限的环境创建一个更小、更快速的BERT版本。</li>
</ul>
<h3 id="10-Longformer">10. <strong>Longformer</strong></h3>
<ul>
<li><strong>关键特性</strong>：Longformer引入了稀疏自注意力机制，每个标记仅关注一个有限的局部窗口，而不是与所有其他标记进行计算。</li>
<li><strong>目的</strong>：专门设计用于高效处理长文档，通过减少自注意力的二次复杂度，降低计算量。</li>
</ul>
<h3 id="11-Linformer">11. <strong>Linformer</strong></h3>
<ul>
<li><strong>关键特性</strong>：Linformer通过低秩矩阵分解来近似自注意力机制，将注意力操作的复杂度从(O(n^2))降低到(O(n))。</li>
<li><strong>目的</strong>：使自注意力机制能够扩展到长序列上。</li>
</ul>
<h3 id="12-Reformer">12. <strong>Reformer</strong></h3>
<ul>
<li><strong>关键特性</strong>：Reformer使用局部敏感哈希（LSH）来减少注意力的复杂性，并使用可逆层来减少内存使用。</li>
<li><strong>目的</strong>：为长序列的处理提供更高效的内存使用，并优化计算效率。</li>
</ul>
<h3 id="13-ELECTRA">13. <strong>ELECTRA</strong></h3>
<ul>
<li><strong>关键特性</strong>：ELECTRA通过生成器和鉴别器来替换预训练中的掩蔽标记。鉴别器预测一个标记是真实的还是被替换的。</li>
<li><strong>目的</strong>：比BERT更加样本高效，可以使用更少的训练资源获得更好的性能。</li>
</ul>
<h3 id="14-DeBERTa（解码增强BERT与解耦注意力）">14. <strong>DeBERTa（解码增强BERT与解耦注意力）</strong></h3>
<ul>
<li><strong>关键特性</strong>：DeBERTa引入了解耦注意力，能够更好地建模位置和相对标记之间的交互。</li>
<li><strong>目的</strong>：通过增强标记之间的依赖关系建模，改进BERT和RoBERTa的性能。</li>
</ul>
<h3 id="15-Swin-Transformer（平移窗口Transformer）">15. <strong>Swin Transformer（平移窗口Transformer）</strong></h3>
<ul>
<li><strong>关键特性</strong>：这是专门为视觉任务设计的Transformer架构，在局部窗口内应用自注意力机制，在层间通过平移窗口捕获全局上下文。</li>
<li><strong>目的</strong>：用于计算机视觉任务，如图像分类，通过分层结构实现高效的图像处理。</li>
</ul>
<h3 id="16-Vision-Transformer（ViT）">16. <strong>Vision Transformer（ViT）</strong></h3>
<ul>
<li><strong>关键特性</strong>：将标准Transformer架构应用于视觉任务，将图像划分为多个小块，将这些小块视为输入序列的标记。</li>
<li><strong>目的</strong>：通过不使用卷积神经网络（CNN）进行图像分类等视觉任务，探索图像处理的新方法。</li>
</ul>
<h3 id="17-Performer">17. <strong>Performer</strong></h3>
<ul>
<li><strong>关键特性</strong>：Performer通过基于核方法的近似来替换传统的自注意力机制，从而提高了计算效率。</li>
<li><strong>目的</strong>：通过近似核方法提高注意力机制的效率，优化计算资源的消耗。</li>
</ul>
<h3 id="18-LaMDA（对话应用的语言模型）">18. <strong>LaMDA（对话应用的语言模型）</strong></h3>
<ul>
<li><strong>关键特性</strong>：由Google设计，LaMDA是一个对话型AI模型，采用针对对话任务优化的Transformer架构。</li>
<li><strong>目的</strong>：生成更加自然和开放式的对话。</li>
</ul>
<h3 id="19-BigBird">19. <strong>BigBird</strong></h3>
<ul>
<li><strong>关键特性</strong>：BigBird是另一个用于长文档的变种，通过组合全局、局部和随机注意力模式来减少计算复杂度。</li>
<li><strong>目的</strong>：高效处理长文档，在内存和计算效率上超越早期的模型。</li>
</ul>
<h3 id="20-稀疏Transformer">20. <strong>稀疏Transformer</strong></h3>
<ul>
<li><strong>关键特性</strong>：稀疏Transformer通过限制标记之间的交互来减少自注意力的计算成本。</li>
<li><strong>目的</strong>：通过使用稀疏注意力模式来高效处理长序列。</li>
</ul>
<h3 id="21-Mistral">21. <strong>Mistral</strong></h3>
<ul>
<li><strong>关键特性</strong>：Mistral是一种高效的密集Transformer模型，设计时考虑了稀疏性和计算效率，旨在比GPT和BERT更轻量。</li>
<li><strong>目的</strong>：在性能和计算效率之间找到平衡，构建更加紧凑的模型。</li>
</ul>
<h3 id="22-Funnel-Transformer">22. <strong>Funnel Transformer</strong></h3>
<ul>
<li><strong>关键特性</strong>：Funnel Transformer使用渐进式降采样机制，将序列长度在层级中逐渐减少，专注于更相关的信息。</li>
<li><strong>目的</strong>：通过逐渐缩减输入序列，在减少计算成本的同时高效地处理长序列。</li>
</ul>
<hr>
<p>这些变种展示了Transformer架构随着时间发展而做出的多种适应和改进，涉及到计算效率、内存使用、长序列处理、以及特定任务的优化等不同方面。其中一些变种专注于提高处理长序列的能力（例如Longformer、Linformer、Reformer），而其他一些则优化了处理特定任务的能力（例如Vision Transformer用于图像，T5用于多任务NLP）。</p>
<h2 id="变长输入">变长输入</h2>
<h3 id="ByteTransformer-A-High-Performance-Transformer-Boosted-for-Variable-Length-Inputs-22-10">ByteTransformer: A High-Performance Transformer Boosted for Variable-Length Inputs (22/10)</h3>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2210.03052">论文地址</a><br>
<a target="_blank" rel="noopener" href="https://github.com/bytedance/ByteTransformer">代码</a><br>
核心思想：在过去的十年里，Transformer已经成为自然语言处理中的关键模型。它们在深度学习应用中非常受欢迎，但transformer模型所需的参数空间的大小越来越大，因此需要相应地加速性能。自然语言处理问题也经常面临可变长度序列，因为句子中的字数通常各不相同。现有的深度学习框架将可变长度序列填充到最大长度，这增加了大量的内存和计算开销。在本文中，介绍了 ByteTransformer，这是一种针对可变长度输入而增强的高性能transformer。我们提出了一种无填充算法，可将整个transformer从零填充标记上的冗余计算中解放出来。除了算法级优化之外，我们还为transformer功能模块提供架构感知优化，尤其是性能关键算法多头注意力 (MHA)。<br>
<img src="ByteTransformer.png" alt=""></p>
<h2 id="模型剪枝">模型剪枝</h2>
<h3 id="What-Matters-in-Transformers-Not-All-Attention-is-Needed-24-06">What Matters in Transformers? Not All Attention is Needed (24/06)</h3>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.15786">论文地址</a><br>
<a target="_blank" rel="noopener" href="https://github.com/CASE-Lab-UMD/LLM-Drop">代码</a><br>
核心思想：虽然扩展基于Transformer的大型语言模型（LLM）在各种任务中表现出了良好的性能，但它也引入了<strong>冗余架构</strong>，给现实世界的部署带来了效率挑战。尽管对LLM中的冗余有一些认识，但transformers中不同架构（如MLP和Attention层）之间的冗余可变性尚未得到充分探索。在这项工作中，我们使用<strong>基于相似性</strong>的度量来研究Transformer中不同模块之间的冗余，包括块、MLP和注意力层。令人惊讶的是，尽管<strong>注意力层</strong>在区分transformers和其他架构方面起着关键作用，但我们发现这些层中的很大一部分表现出<strong>过高的相似性</strong>，可以在不降低性能的情况下进行修剪。例如，Llama-2-70B通过<strong>修剪一半</strong>的注意力层，实现了48.4%的加速，性能仅下降了2.4%。此外，通过在整个训练过程中跟踪模型检查点，我们观察到<strong>注意力层冗余是固有的</strong>，并且在训练阶段是一致的。此外，我们还提出了一种<strong>联合丢弃Attention和MLP层的方法</strong>，使我们能够更积极地丢弃其他层。例如，当丢弃<strong>31层</strong>（Attention+MLP）时，Llama-2-13B在MMLU任务上仍然保留了90%的性能。我们的工作为未来的网络架构设计提供了宝贵的见解。<br>
<img src="LLM-drop.png" alt=""></p>
<h2 id="LLM模型">LLM模型</h2>
<h3 id="Efficient-Streaming-Language-Models-with-Attention-Sinks-23-09">Efficient Streaming Language Models with Attention Sinks (23/09)</h3>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2309.17453">论文地址</a><br>
<a target="_blank" rel="noopener" href="https://github.com/mit-han-lab/streaming-llm">代码</a><br>
核心思想：在多轮对话等需要长时间交互的流式应用中部署大型语言模型 (LLM) 迫在眉睫，但面临两大挑战。首先，在解码阶段，<strong>缓存</strong>先前标记的键和值状态 (KV) 会消耗大量内存。其次，流行的 LLM <strong>无法推广</strong>到比训练序列长度更长的文本。窗口注意（仅缓存最近的 KV）是一种自然的方法 - 但我们表明，当<strong>文本长度超过缓存大小</strong>时，它会失败。我们观察到一个有趣的现象，即注意力下沉，即<strong>保留初始标记的 KV</strong> 将在很大程度上恢复窗口注意的性能。在本文中，我们首先证明注意力下沉的出现是由于<strong>对初始标记作为“下沉”的强烈注意力得分</strong>，即使它们在语义上并不重要。基于上述分析，我们引入了 StreamingLLM，这是一个高效的框架，它使使用有限长度注意力窗口训练的 LLM 能够推广到无限序列长度而无需任何微调。我们表明，StreamingLLM 可使 Llama-2、MPT、Falcon 和 Pythia 使用多达 400 万个或更多的标记执行稳定而高效的语言建模。此外，我们发现在预训练期间添加占位符标记作为专用的注意力接收器可以进一步改善流式部署。在流式设置中，StreamingLLM 的表现优于滑动窗口重新计算基线，速度提高高达 22.2 倍。<br>
<img src="streamingLLM.png" alt=""></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://SergeWang.github.io">Serge Wang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://sergewang.github.io/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B8%80%EF%BC%9ATransformer%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/">https://sergewang.github.io/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B8%80%EF%BC%9ATransformer%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://SergeWang.github.io" target="_blank">Model The World</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%BB%BC%E8%BF%B0/">综述</a><a class="post-meta__tags" href="/tags/Transformer/">Transformer</a></div><div class="post-share"><div class="social-share" data-image="/images/transformer.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2024/11/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E4%B8%89%E5%8D%81%E4%B9%9D%EF%BC%9ASAMURAI%EF%BC%9A%E7%94%A8%E4%BA%8E%E9%9B%B6%E6%A0%B7%E6%9C%AC%E8%A7%86%E8%A7%89%E8%BF%BD%E8%B8%AA%E7%9A%84%E5%85%B7%E6%9C%89%E8%BF%90%E5%8A%A8%E6%84%9F%E7%9F%A5%E8%AE%B0%E5%BF%86%E7%9A%84%E8%87%AA%E9%80%82%E5%BA%94SAM/" title="论文阅读三十九：SAMURAI：用于零样本视觉追踪的具有运动感知记忆的自适应SAM"><img class="cover" src="/images/SAMRUAI.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">论文阅读三十九：SAMURAI：用于零样本视觉追踪的具有运动感知记忆的自适应SAM</div></div><div class="info-2"><div class="info-item-1">摘要 分割一切模型 2（SAM2）在目标分割任务上已经展示强大性能，但在视觉目标追踪中面临挑战，尤其当处理具有快速移动或自遮挡的物体的拥挤场景时。此外，原始模型中固定窗口的记忆方法未考虑选择用于下一帧调节的图像特征的记忆的质量，导致视频中的误差传播。本文介绍SAMURAI，SAM2的增强适应性版，专为视觉目标跟踪而设计。通过结合时间运动线索和提出的运动感知记忆选择机制，SAMURAI有效地预测目标运动，并优化掩码选择，无需再训练或微调，取得稳健精确追踪。SAMURAI实时操作，并在各种基准数据集上展示强大的零样本性能，说明了它的无需微调的泛化能力。评估中，SAMURAI在现有追踪器的成功率和精度上取得显著改进， LaSOTextLaSOT_{ext}LaSOText​上增益为 7.1%， GOT-10k上增益3.5%。而且，它相较于LaSOT上的全监督方法取得竞争性的结果，突出了它在复杂追踪场景的健壮性，以及它在真实世界动态环境应用上的潜力。代码和结果在： https://github.com/yangchris11/samurai...</div></div></div></a><a class="pagination-related" href="/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B8%89%EF%BC%9A%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0%E5%8F%8A%E5%85%B6%E6%96%B9%E6%B3%95/" title="综述三：持续学习及其方法"><img class="cover" src="/images/mamba.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">综述三：持续学习及其方法</div></div><div class="info-2"><div class="info-item-1">持续学习（Continual Learning，CL），也称为终身学习（Lifelong Learning），指的是模型能够从持续不断的数据流中学习，并随着时间的推移不断适应和获得新知识，而不会遗忘先前学习的内容。持续学习面临的一个主要挑战是灾难性遗忘（Catastrophic Forgetting），即在学习新任务时，模型容易遗忘之前学习的任务。 为了应对这些挑战，提出了多种方法，这些方法可以根据它们如何处理遗忘、如何存储知识以及如何使用新数据进行分类。 下面是主要的持续学习方法，按它们所采用的主要策略进行组织： 1....</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B8%89%EF%BC%9A%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0%E5%8F%8A%E5%85%B6%E6%96%B9%E6%B3%95/" title="综述三：持续学习及其方法"><img class="cover" src="/images/mamba.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-24</div><div class="info-item-2">综述三：持续学习及其方法</div></div><div class="info-2"><div class="info-item-1">持续学习（Continual Learning，CL），也称为终身学习（Lifelong Learning），指的是模型能够从持续不断的数据流中学习，并随着时间的推移不断适应和获得新知识，而不会遗忘先前学习的内容。持续学习面临的一个主要挑战是灾难性遗忘（Catastrophic Forgetting），即在学习新任务时，模型容易遗忘之前学习的任务。 为了应对这些挑战，提出了多种方法，这些方法可以根据它们如何处理遗忘、如何存储知识以及如何使用新数据进行分类。 下面是主要的持续学习方法，按它们所采用的主要策略进行组织： 1....</div></div></div></a><a class="pagination-related" href="/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B8%83%EF%BC%9ACNN%E6%A8%A1%E5%9E%8B/" title="综述七：CNN模型"><img class="cover" src="/images/mamba.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-24</div><div class="info-item-2">综述七：CNN模型</div></div><div class="info-2"><div class="info-item-1">Here’s a list of major CNN (Convolutional Neural Network) variants ordered by the time of their publication. CNNs have evolved over the years to improve accuracy, reduce computational costs, and adapt to different domains.  1. LeNet (1998)  Key Idea: One of the first CNN architectures, designed for handwritten digit recognition (MNIST). It used convolutional layers followed by pooling and fully connected layers. Application: Digit classification. Notable Paper: Yann LeCun et al.,...</div></div></div></a><a class="pagination-related" href="/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B9%9D%EF%BC%9ALLM/" title="综述九：LLM"><img class="cover" src="/images/mamba.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-24</div><div class="info-item-2">综述九：LLM</div></div><div class="info-2"><div class="info-item-1">提示（Prompts） Large Lanuage Models Can Self-Improve in Long-context Reasoning (24/10) 论文地址 核心思想：大型语言模型（LLM）在处理长上下文方面取得了实质性进展，但在长上下文推理方面仍存在困难。现有的方法通常涉及使用合成数据对LLM进行微调，这取决于人类专家的注释或GPT-4等高级模型，从而限制了进一步的进步。为了解决这个问题，研究了LLM在长上下文推理中自我改进的潜力，并提出了专门为此目的设计的SEALONG方法。这种方法很简单：对每个问题的多个输出进行采样，用最小贝叶斯风险对其进行评分，然后根据这些输出进行监督微调或偏好优化。在几个领先的LLM上进行的广泛实验证明了SEALONG的有效性，Llama-3.1-8B-Instruct的绝对提高了4.2分。此外，与依赖于人类专家或高级模型生成的数据的先前方法相比，SEALONG实现了更优的性能。我们预计，这项工作将为长期情景下的自我提升技术开辟新的途径，这对LLM的持续发展至关重要。 </div></div></div></a><a class="pagination-related" href="/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%B9%9D%EF%BC%9AMamba%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/" title="综述九：Mamba及其变体"><img class="cover" src="/images/mamba.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-24</div><div class="info-item-2">综述九：Mamba及其变体</div></div><div class="info-2"><div class="info-item-1">SSM模型 Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention (20/06) 论文地址 核心思想：将自注意表示为核特征图的线性点积，并使用矩阵乘法的结合属性将复杂度从 O(N2)\mathcal{O}(N^2)O(N2) 减少到 O(N)\mathcal{O}(N)O(N) ，其中N是序列长度。我们证明，这个公式允许迭代实现，大大加速了自回归Transformers，并揭示了它们与循环神经网络的关系。(一种涉及循环的自我注意近似，可以看作是退化的线性SSM)  Hungry Hungry Hippos: Towards Language Modeling with State Space Models...</div></div></div></a><a class="pagination-related" href="/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%BA%8C%EF%BC%9ADiTs%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93/" title="综述二：DiTs及其变体"><img class="cover" src="/images/SIT.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-24</div><div class="info-item-2">综述二：DiTs及其变体</div></div><div class="info-2"><div class="info-item-1">**DiT（去噪扩散Transformer模型）**是结合了Transformer架构和扩散模型的一类生成模型，特别专注于在扩散框架内的去噪过程。扩散模型通过逐步添加和去除噪声的过程来建模复杂的分布，近年来在生成任务中非常流行。 下面是一些著名的DiT变种，它们在不同方面扩展了原始的DiT模型： 1. DiT（原始版本）  关键特性：原始的DiT模型将Transformer架构与去噪扩散过程结合，利用Transformer的注意力机制改进生成质量和训练的可扩展性。 目的：生成高质量的图像，并与传统的卷积神经网络相比，提高训练效率。  2. DiT++（增强版DiT）  关键特性：DiT++是在原始DiT基础上进行增强的版本，可能包括模型架构的改进、训练方法的优化或额外的正则化技术。 目的：通过改进Transformer架构和扩散过程中的噪声调度，提升生成稳定性和性能。  3....</div></div></div></a><a class="pagination-related" href="/2024/11/24/%E7%BB%BC%E8%BF%B0%E4%BA%94%EF%BC%9A%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%8F%8A%E5%85%B6%E5%88%86%E7%B1%BB/" title="综述五：强化学习及其分类"><img class="cover" src="/images/mamba.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-24</div><div class="info-item-2">综述五：强化学习及其分类</div></div><div class="info-2"><div class="info-item-1">强化学习的变种 强化学习（Reinforcement Learning，简称RL）是一种机器学习方法，其中代理（Agent）通过与环境的交互来学习做出决策。代理的目标是通过采取适当的行动，最大化长期累积的奖励。强化学习是一个广泛的领域，许多不同的变种和算法已被开发出来，以解决学习、探索和决策等不同方面的问题。 以下是强化学习的主要变种及其子类别：  1. 无模型 vs 有模型强化学习  无模型强化学习（Model-Free RL）：代理不构建或使用环境的动态模型，而是直接通过与环境的交互来学习。  示例：  Q学习（Q-Learning，包括表格化和深度Q学习） 策略梯度方法（例如，REINFORCE） Actor-Critic方法（例如A3C，PPO）     有模型强化学习（Model-Based RL）：代理试图学习环境的转移动态和奖励函数，并利用这些模型来做出更有信息量的决策。  示例：  Dyna-Q（Q学习与规划结合） World Models 蒙特卡洛树搜索（MCTS）       2....</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/newlogo.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Serge Wang</div><div class="author-info-description">今日事，今日毕</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">74</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">43</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">20</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/SergeWang"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/SergeWang" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:sergew027@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">Welcome to my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%8E%9F%E5%A7%8BTransformer-Vanilla-Transformer"><span class="toc-number">1.</span> <span class="toc-text">1. 原始Transformer (Vanilla Transformer)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-BERT%EF%BC%88%E5%8F%8C%E5%90%91%E7%BC%96%E7%A0%81%E5%99%A8%E8%A1%A8%E7%A4%BA%EF%BC%89"><span class="toc-number">2.</span> <span class="toc-text">2. BERT（双向编码器表示）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-GPT%EF%BC%88%E7%94%9F%E6%88%90%E5%BC%8F%E9%A2%84%E8%AE%AD%E7%BB%83Transformer%EF%BC%89"><span class="toc-number">3.</span> <span class="toc-text">3. GPT（生成式预训练Transformer）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-T5%EF%BC%88%E6%96%87%E6%9C%AC%E5%88%B0%E6%96%87%E6%9C%AC%E7%9A%84%E4%BC%A0%E8%BE%93Transformer%EF%BC%89"><span class="toc-number">4.</span> <span class="toc-text">4. T5（文本到文本的传输Transformer）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-Transformer-XL%EF%BC%88%E6%89%A9%E5%B1%95%E9%95%BF%E5%BA%8F%E5%88%97Transformer%EF%BC%89"><span class="toc-number">5.</span> <span class="toc-text">5. Transformer-XL（扩展长序列Transformer）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-XLNet"><span class="toc-number">6.</span> <span class="toc-text">6. XLNet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-RoBERTa%EF%BC%88%E9%B2%81%E6%A3%92%E4%BC%98%E5%8C%96%E7%9A%84BERT%EF%BC%89"><span class="toc-number">7.</span> <span class="toc-text">7. RoBERTa（鲁棒优化的BERT）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-ALBERT%EF%BC%88%E8%BD%BB%E9%87%8F%E5%8C%96BERT%EF%BC%89"><span class="toc-number">8.</span> <span class="toc-text">8. ALBERT（轻量化BERT）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-DistilBERT"><span class="toc-number">9.</span> <span class="toc-text">9. DistilBERT</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-Longformer"><span class="toc-number">10.</span> <span class="toc-text">10. Longformer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-Linformer"><span class="toc-number">11.</span> <span class="toc-text">11. Linformer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-Reformer"><span class="toc-number">12.</span> <span class="toc-text">12. Reformer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-ELECTRA"><span class="toc-number">13.</span> <span class="toc-text">13. ELECTRA</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#14-DeBERTa%EF%BC%88%E8%A7%A3%E7%A0%81%E5%A2%9E%E5%BC%BABERT%E4%B8%8E%E8%A7%A3%E8%80%A6%E6%B3%A8%E6%84%8F%E5%8A%9B%EF%BC%89"><span class="toc-number">14.</span> <span class="toc-text">14. DeBERTa（解码增强BERT与解耦注意力）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#15-Swin-Transformer%EF%BC%88%E5%B9%B3%E7%A7%BB%E7%AA%97%E5%8F%A3Transformer%EF%BC%89"><span class="toc-number">15.</span> <span class="toc-text">15. Swin Transformer（平移窗口Transformer）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#16-Vision-Transformer%EF%BC%88ViT%EF%BC%89"><span class="toc-number">16.</span> <span class="toc-text">16. Vision Transformer（ViT）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-Performer"><span class="toc-number">17.</span> <span class="toc-text">17. Performer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#18-LaMDA%EF%BC%88%E5%AF%B9%E8%AF%9D%E5%BA%94%E7%94%A8%E7%9A%84%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%89"><span class="toc-number">18.</span> <span class="toc-text">18. LaMDA（对话应用的语言模型）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#19-BigBird"><span class="toc-number">19.</span> <span class="toc-text">19. BigBird</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#20-%E7%A8%80%E7%96%8FTransformer"><span class="toc-number">20.</span> <span class="toc-text">20. 稀疏Transformer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#21-Mistral"><span class="toc-number">21.</span> <span class="toc-text">21. Mistral</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-Funnel-Transformer"><span class="toc-number">22.</span> <span class="toc-text">22. Funnel Transformer</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%98%E9%95%BF%E8%BE%93%E5%85%A5"><span class="toc-number"></span> <span class="toc-text">变长输入</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ByteTransformer-A-High-Performance-Transformer-Boosted-for-Variable-Length-Inputs-22-10"><span class="toc-number">1.</span> <span class="toc-text">ByteTransformer: A High-Performance Transformer Boosted for Variable-Length Inputs (22&#x2F;10)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D"><span class="toc-number"></span> <span class="toc-text">模型剪枝</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#What-Matters-in-Transformers-Not-All-Attention-is-Needed-24-06"><span class="toc-number">1.</span> <span class="toc-text">What Matters in Transformers? Not All Attention is Needed (24&#x2F;06)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LLM%E6%A8%A1%E5%9E%8B"><span class="toc-number"></span> <span class="toc-text">LLM模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Efficient-Streaming-Language-Models-with-Attention-Sinks-23-09"><span class="toc-number">1.</span> <span class="toc-text">Efficient Streaming Language Models with Attention Sinks (23&#x2F;09)</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/12/17/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E4%BA%94%E5%8D%81%EF%BC%9A%E5%AD%97%E8%8A%82%E6%BD%9C%E5%9C%A8Transformer%EF%BC%9APatches%E6%AF%94Tokens%E6%89%A9%E5%B1%95%E6%80%A7%E5%A5%BD/" title="论文阅读五十：字节潜在Transformer：Patches比Tokens扩展性好"><img src="/images/BLT.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文阅读五十：字节潜在Transformer：Patches比Tokens扩展性好"/></a><div class="content"><a class="title" href="/2024/12/17/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E4%BA%94%E5%8D%81%EF%BC%9A%E5%AD%97%E8%8A%82%E6%BD%9C%E5%9C%A8Transformer%EF%BC%9APatches%E6%AF%94Tokens%E6%89%A9%E5%B1%95%E6%80%A7%E5%A5%BD/" title="论文阅读五十：字节潜在Transformer：Patches比Tokens扩展性好">论文阅读五十：字节潜在Transformer：Patches比Tokens扩展性好</a><time datetime="2024-12-17T11:15:34.000Z" title="发表于 2024-12-17 19:15:34">2024-12-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/12/17/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9B%9B%E5%8D%81%E4%B9%9D%EF%BC%9A%E5%A4%A7%E5%9E%8B%E6%A6%82%E5%BF%B5%E6%A8%A1%E5%9E%8B%EF%BC%9A%E5%8F%A5%E5%AD%90%E8%A1%A8%E7%A4%BA%E7%A9%BA%E9%97%B4%E4%B8%AD%E7%9A%84%E8%AF%AD%E8%A8%80%E5%BB%BA%E6%A8%A1/" title="论文阅读四十九：大型概念模型：句子表示空间中的语言建模"><img src="/images/LCM.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文阅读四十九：大型概念模型：句子表示空间中的语言建模"/></a><div class="content"><a class="title" href="/2024/12/17/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9B%9B%E5%8D%81%E4%B9%9D%EF%BC%9A%E5%A4%A7%E5%9E%8B%E6%A6%82%E5%BF%B5%E6%A8%A1%E5%9E%8B%EF%BC%9A%E5%8F%A5%E5%AD%90%E8%A1%A8%E7%A4%BA%E7%A9%BA%E9%97%B4%E4%B8%AD%E7%9A%84%E8%AF%AD%E8%A8%80%E5%BB%BA%E6%A8%A1/" title="论文阅读四十九：大型概念模型：句子表示空间中的语言建模">论文阅读四十九：大型概念模型：句子表示空间中的语言建模</a><time datetime="2024-12-17T11:13:10.000Z" title="发表于 2024-12-17 19:13:10">2024-12-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/12/17/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9B%9B%E5%8D%81%E5%85%AB%EF%BC%9A%E5%85%8D%E8%AE%AD%E7%BB%83%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%A0%87%E7%AD%BE%E4%BD%9C%E4%B8%BA%E7%89%B9%E5%BE%81%E7%9A%84%E5%8A%9B%E9%87%8F/" title="论文阅读四十八：免训练图神经网络和标签作为特征的力量"><img src="/images/tfgnn.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文阅读四十八：免训练图神经网络和标签作为特征的力量"/></a><div class="content"><a class="title" href="/2024/12/17/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9B%9B%E5%8D%81%E5%85%AB%EF%BC%9A%E5%85%8D%E8%AE%AD%E7%BB%83%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%A0%87%E7%AD%BE%E4%BD%9C%E4%B8%BA%E7%89%B9%E5%BE%81%E7%9A%84%E5%8A%9B%E9%87%8F/" title="论文阅读四十八：免训练图神经网络和标签作为特征的力量">论文阅读四十八：免训练图神经网络和标签作为特征的力量</a><time datetime="2024-12-17T11:09:52.000Z" title="发表于 2024-12-17 19:09:52">2024-12-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/12/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9B%9B%E5%8D%81%E4%B8%83%EF%BC%9A3DGS-zip-3D%E9%AB%98%E6%96%AF%E6%B3%BC%E6%BA%85%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%E7%BB%BC%E8%BF%B0/" title="论文阅读四十七：3DGS.zip:3D高斯泼溅压缩方法综述"><img src="/images/3dgszip.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文阅读四十七：3DGS.zip:3D高斯泼溅压缩方法综述"/></a><div class="content"><a class="title" href="/2024/12/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9B%9B%E5%8D%81%E4%B8%83%EF%BC%9A3DGS-zip-3D%E9%AB%98%E6%96%AF%E6%B3%BC%E6%BA%85%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%E7%BB%BC%E8%BF%B0/" title="论文阅读四十七：3DGS.zip:3D高斯泼溅压缩方法综述">论文阅读四十七：3DGS.zip:3D高斯泼溅压缩方法综述</a><time datetime="2024-12-07T03:44:18.000Z" title="发表于 2024-12-07 11:44:18">2024-12-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/12/01/%E7%BB%BC%E8%BF%B0%E5%8D%81%EF%BC%9A%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B/" title="综述十：多模态模型"><img src="/images/mamba.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="综述十：多模态模型"/></a><div class="content"><a class="title" href="/2024/12/01/%E7%BB%BC%E8%BF%B0%E5%8D%81%EF%BC%9A%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B/" title="综述十：多模态模型">综述十：多模态模型</a><time datetime="2024-12-01T11:04:52.000Z" title="发表于 2024-12-01 19:04:52">2024-12-01</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2024 By Serge Wang</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (false) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>