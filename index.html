<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Model The World</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="学习笔记">
<meta property="og:type" content="website">
<meta property="og:title" content="Model The World">
<meta property="og:url" content="https://sergewang.github.io/">
<meta property="og:site_name" content="Model The World">
<meta property="og:description" content="学习笔记">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Serge Wang">
<meta property="article:tag" content="机器学习 人工智能  深度学习 Python C&#x2F;C++ Rust 数据分析">
<meta name="twitter:card" content="summary">
  
  
    <link rel="shortcut icon" href="/logo.ico">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css">

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Model The World</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Serge&#39;s blogs</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        
        
        <a class="nav-icon nav-search-btn" title="Suche"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Suche"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://SergeWang.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-关于-CNF-中时间依赖微分同胚映射的理解" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/10/28/%E5%85%B3%E4%BA%8E-CNF-%E4%B8%AD%E6%97%B6%E9%97%B4%E4%BE%9D%E8%B5%96%E5%BE%AE%E5%88%86%E5%90%8C%E8%83%9A%E6%98%A0%E5%B0%84%E7%9A%84%E7%90%86%E8%A7%A3/" class="article-date">
  <time class="dt-published" datetime="2024-10-28T06:10:07.000Z" itemprop="datePublished">2024-10-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Diffusion-Model/">Diffusion Model</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/10/28/%E5%85%B3%E4%BA%8E-CNF-%E4%B8%AD%E6%97%B6%E9%97%B4%E4%BE%9D%E8%B5%96%E5%BE%AE%E5%88%86%E5%90%8C%E8%83%9A%E6%98%A0%E5%B0%84%E7%9A%84%E7%90%86%E8%A7%A3/">关于 CNF 中时间依赖微分同胚映射的理解</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="关于-CNF-中时间依赖微分同胚映射的理解"><a href="#关于-CNF-中时间依赖微分同胚映射的理解" class="headerlink" title="关于 CNF 中时间依赖微分同胚映射的理解"></a>关于 CNF 中时间依赖微分同胚映射的理解</h2><p>在连续归一化流 (CNF) 中，时间依赖微分同胚映射是将简单分布（如标准正态分布）转化为复杂数据分布的关键机制。它通过一个随时间变化的向量场 vt(x) 来实现，这个向量场决定了概率密度函数从初始分布 p0(x) 到目标分布 p1(x) 的演化过程。这个演化过程可以通过一个微分同胚映射 φt 来描述，它将时间 t 的概率密度函数 pt(x)  “推” 向时间 t+dt 的概率密度函数 pt+dt(x)。</p>
<h3 id="微分同胚映射的定义"><a href="#微分同胚映射的定义" class="headerlink" title="微分同胚映射的定义"></a>微分同胚映射的定义</h3><p>微分同胚映射 φt 拥有以下性质：</p>
<ul>
<li><strong>双射:</strong>  φt 是一个一一映射，也就是说，对于每一个 x，都有唯一一个 y 与之对应，反之亦然。</li>
<li><strong>可微:</strong>  φt 和它的逆映射 φ−1t  都是可微的，这意味着它们是光滑且连续的。</li>
<li><strong>保向:</strong>  φt 保持空间的方向，也就是说，它不会翻转或扭曲空间。</li>
</ul>
<p>这些性质保证了 φt 可以将一个概率密度函数平滑地转化为另一个概率密度函数，并且不会丢失任何信息。</p>
<h3 id="微分同胚映射的构建"><a href="#微分同胚映射的构建" class="headerlink" title="微分同胚映射的构建"></a>微分同胚映射的构建</h3><p>微分同胚映射 φt 是通过求解以下常微分方程 (ODE) 得到的:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">d/dt φt(x) = vt(φt(x)) </span><br><span class="line">φ0(x) = x</span><br></pre></td></tr></table></figure>

<p>其中 vt(x) 是 CNF 模型学习到的时间依赖向量场。这个 ODE 描述了在向量场 vt(x) 的作用下，点 x 随时间的运动轨迹。φt(x)  则表示从初始时刻 t&#x3D;0 开始，沿着这条轨迹运动到时间 t 时所到达的点。</p>
<h3 id="连续性方程的作用"><a href="#连续性方程的作用" class="headerlink" title="连续性方程的作用"></a>连续性方程的作用</h3><p>连续性方程可以用来验证向量场  vt(x) 是否能够正确地引导概率密度函数的演化。它表明概率密度的变化率必须与其“流动”情况相互抵消，以保证总概率守恒。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>时间依赖微分同胚映射是 CNF 模型的核心概念之一，它通过一个随时间变化的向量场来实现概率密度函数的平滑转化。连续性方程则确保了这个转化过程的有效性。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://sergewang.github.io/2024/10/28/%E5%85%B3%E4%BA%8E-CNF-%E4%B8%AD%E6%97%B6%E9%97%B4%E4%BE%9D%E8%B5%96%E5%BE%AE%E5%88%86%E5%90%8C%E8%83%9A%E6%98%A0%E5%B0%84%E7%9A%84%E7%90%86%E8%A7%A3/" data-id="cm2smfiqt0000dkvx1gqsg1ce" data-title="关于 CNF 中时间依赖微分同胚映射的理解" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" rel="tag">人工智能</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/" rel="tag">扩散模型</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-对连续性方程的深入解读" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/10/28/%E5%AF%B9%E8%BF%9E%E7%BB%AD%E6%80%A7%E6%96%B9%E7%A8%8B%E7%9A%84%E6%B7%B1%E5%85%A5%E8%A7%A3%E8%AF%BB/" class="article-date">
  <time class="dt-published" datetime="2024-10-28T06:07:01.000Z" itemprop="datePublished">2024-10-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Diffusion-Model/">Diffusion Model</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/10/28/%E5%AF%B9%E8%BF%9E%E7%BB%AD%E6%80%A7%E6%96%B9%E7%A8%8B%E7%9A%84%E6%B7%B1%E5%85%A5%E8%A7%A3%E8%AF%BB/">对连续性方程的深入解读</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>我理解您对连续性方程仍有困惑，我会尽力为您详细解释。连续性方程本质上是一个描述守恒量的方程。在流匹配的语境下，这个守恒量就是概率密度。 </p>
<h3 id="概率密度的守恒"><a href="#概率密度的守恒" class="headerlink" title="概率密度的守恒"></a>概率密度的守恒</h3><p>想象一下液体在管道中流动。如果液体不可压缩，那么无论管道粗细如何变化，单位时间内流过任何一个截面的液体总量都应该保持不变。这就是质量守恒定律的体现。</p>
<p>概率密度也遵循类似的守恒原则。假设我们有一个概率密度函数 pt(x)，它描述了在时间 t 时，随机变量 X 取值 x 的概率密度。随着时间的推移，pt(x) 的形状可能会发生变化，但它所代表的总概率必须保持为 1。</p>
<p>连续性方程正是用来描述概率密度这种守恒特性的数学工具。</p>
<h3 id="连续性方程的数学表达"><a href="#连续性方程的数学表达" class="headerlink" title="连续性方程的数学表达"></a>连续性方程的数学表达</h3><p>连续性方程的表达式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d/dt pt(x) + div(pt(x)vt(x)) = 0 </span><br></pre></td></tr></table></figure>

<ul>
<li><strong>d&#x2F;dt pt(x)</strong> 表示概率密度函数 pt(x) 随时间的变化率。</li>
<li><strong>div(pt(x)vt(x))</strong> 表示概率密度的“流动”情况，其中 vt(x) 是一个向量场，描述了概率密度在空间中的运动方向和速度。散度算子 div 则度量了向量场在某一点的“扩张”或“收缩”程度。</li>
</ul>
<p><strong>连续性方程的意义：</strong></p>
<ul>
<li>如果 d&#x2F;dt pt(x) 为正，说明在 x 点的概率密度正在增加，这可能是由于周围的概率密度流入了 x 点。</li>
<li>如果 div(pt(x)vt(x)) 为负，说明在 x 点的概率密度正在减少，这可能是由于 x 点的概率密度流向了周围。</li>
</ul>
<p>连续性方程指出，概率密度的变化率与概率密度的“流动”情况必须相互抵消，以保证总概率守恒。</p>
<h3 id="连续性方程在流匹配中的应用"><a href="#连续性方程在流匹配中的应用" class="headerlink" title="连续性方程在流匹配中的应用"></a>连续性方程在流匹配中的应用</h3><p>在流匹配中，我们希望训练一个连续归一化流 (CNF) 模型，使其能够生成与目标数据分布相似的样本。这个 CNF 模型可以用一个向量场 vt(x) 来表示，它决定了概率密度函数从初始分布 p0(x) 到目标分布 p1(x) 的演化过程。</p>
<p>连续性方程的作用就是确保 CNF 模型所定义的向量场 vt(x) 能够正确地引导概率密度函数的演化，并最终生成我们期望的目标分布。</p>
<p><strong>具体来说，连续性方程的应用体现在以下几个方面：</strong></p>
<ol>
<li><strong>验证模型的有效性：</strong> 通过检查学习到的向量场 vt(x) 是否满足连续性方程，我们可以判断 CNF 模型是否能够生成有效的概率路径。</li>
<li><strong>设计训练目标函数：</strong>  一些流匹配的训练目标函数的设计是基于连续性方程的。例如，条件流匹配 (CFM) 的目标函数就是为了最小化模型向量场与目标向量场之间的差异，而目标向量场的构建正是基于连续性方程。</li>
<li><strong>计算模型的概率密度：</strong> 利用连续性方程和流的轨迹方程，我们可以推导出计算 CNF 模型在任意数据点概率密度的方法。</li>
</ol>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>连续性方程是理解流匹配的关键概念之一。它提供了一种数学工具来描述概率密度的守恒特性，并确保 CNF 模型能够生成有效的概率路径。 </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://sergewang.github.io/2024/10/28/%E5%AF%B9%E8%BF%9E%E7%BB%AD%E6%80%A7%E6%96%B9%E7%A8%8B%E7%9A%84%E6%B7%B1%E5%85%A5%E8%A7%A3%E8%AF%BB/" data-id="cm2smfiqx0001dkvx8xmv3gjr" data-title="对连续性方程的深入解读" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" rel="tag">人工智能</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/" rel="tag">扩散模型</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-连续性方程在流匹配中的理解" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/10/28/%E8%BF%9E%E7%BB%AD%E6%80%A7%E6%96%B9%E7%A8%8B%E5%9C%A8%E6%B5%81%E5%8C%B9%E9%85%8D%E4%B8%AD%E7%9A%84%E7%90%86%E8%A7%A3/" class="article-date">
  <time class="dt-published" datetime="2024-10-28T06:05:27.000Z" itemprop="datePublished">2024-10-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Diffusion-Model/">Diffusion Model</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/10/28/%E8%BF%9E%E7%BB%AD%E6%80%A7%E6%96%B9%E7%A8%8B%E5%9C%A8%E6%B5%81%E5%8C%B9%E9%85%8D%E4%B8%AD%E7%9A%84%E7%90%86%E8%A7%A3/">连续性方程在流匹配中的理解</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="连续性方程在流匹配中的理解"><a href="#连续性方程在流匹配中的理解" class="headerlink" title="连续性方程在流匹配中的理解"></a>连续性方程在流匹配中的理解</h2><p>连续性方程是偏微分方程 (PDE)，它提供了一个必要且充分的条件，以确保向量场 vt 生成概率路径 pt。 换句话说，它验证了给定的向量场是否确实生成了期望的概率密度演变。</p>
<p><strong>连续性方程：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d/dt pt(x) + div(pt(x)vt(x)) = 0 </span><br></pre></td></tr></table></figure>

<p>其中：</p>
<ul>
<li>pt(x) 是时间 t 的概率密度函数。</li>
<li>vt(x) 是时间 t 的向量场。</li>
<li>div 是关于空间变量 x &#x3D; (x1, …, xd) 的散度算子，即  div &#x3D;  ∑d i&#x3D;1 ∂&#x2F;∂xi 。</li>
</ul>
<p><strong>连续性方程在流匹配中的作用：</strong></p>
<ul>
<li><strong>验证向量场：</strong> 连续性方程用于检验学习到的 CNF 模型的向量场 vt 是否确实生成了目标概率路径 pt(x)。</li>
<li><strong>证明定理：</strong> 在证明流匹配的相关定理时，连续性方程起着关键作用。例如，在定理 1 的证明中，通过验证边际概率路径 pt 和边际向量场 ut 满足连续性方程，可以证明 ut 确实生成了 pt。</li>
</ul>
<p><strong>计算 CNF 模型的概率：</strong></p>
<p>连续性方程与流动的轨迹方程 (d&#x2F;dt φt(x) &#x3D; vt(φt(x))) 结合，可以推导出瞬时变量的变化，并最终得到计算 CNF 模型在任意数据点 x1 概率的方法。</p>
<p><strong>总结:</strong></p>
<p>连续性方程在流匹配中扮演着重要的角色，它不仅用于验证向量场，还在理论证明和概率计算中发挥着关键作用。 </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://sergewang.github.io/2024/10/28/%E8%BF%9E%E7%BB%AD%E6%80%A7%E6%96%B9%E7%A8%8B%E5%9C%A8%E6%B5%81%E5%8C%B9%E9%85%8D%E4%B8%AD%E7%9A%84%E7%90%86%E8%A7%A3/" data-id="cm2smfiqz0003dkvx70xv71hv" data-title="连续性方程在流匹配中的理解" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" rel="tag">人工智能</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/" rel="tag">扩散模型</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-流匹配 (Flow Matching) 简介" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/10/28/%E6%B5%81%E5%8C%B9%E9%85%8D%20(Flow%20Matching)%20%E7%AE%80%E4%BB%8B/" class="article-date">
  <time class="dt-published" datetime="2024-10-28T06:00:01.000Z" itemprop="datePublished">2024-10-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Diffusion-Model/">Diffusion Model</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/10/28/%E6%B5%81%E5%8C%B9%E9%85%8D%20(Flow%20Matching)%20%E7%AE%80%E4%BB%8B/">流匹配 (Flow Matching) 简介</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>流匹配 (FM) 是一种用于训练连续归一化流 (CNF) 的新方法，它能够以空前的规模训练 CNF。它基于一种称为“条件概率路径”的概念，该路径描述了从噪声样本到数据样本的转换过程。FM 的目标是通过回归固定条件概率路径的向量场来匹配该目标概率路径，而无需进行昂贵的模拟。</p>
<h3 id="条件流匹配-CFM"><a href="#条件流匹配-CFM" class="headerlink" title="条件流匹配 (CFM)"></a>条件流匹配 (CFM)</h3><p>为了使 FM 更加易于处理，引入了条件流匹配 (CFM) 的概念。CFM 避免了对难以处理的积分的依赖，并使用每个样本定义的概率路径和向量场。</p>
<p><strong>CFM 目标函数：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LCFM(θ) = Et,q(x1),p(x0) ||| vt(ψt(x0)) - d/dt ψt(x0) |||² </span><br></pre></td></tr></table></figure>

<p>其中：</p>
<ul>
<li>θ 是 CNF 向量场的可学习参数。</li>
<li>t ∼ U（均匀分布）。</li>
<li>x1 是服从未知数据分布 q(x1) 的随机变量。</li>
<li>x0 ∼ p(x0) 是服从简单分布的随机变量，例如标准正态分布。</li>
<li>ψt 是与条件概率路径 pt(x|x1) 对应的流映射。</li>
<li>vt 是 CNF 向量场。</li>
</ul>
<p><strong>CFM 的优势：</strong></p>
<ul>
<li>与原始 FM 目标函数具有相同的最佳值。</li>
<li>不需要显式了解难以处理的目标向量场。</li>
</ul>
<h3 id="条件概率路径和向量场"><a href="#条件概率路径和向量场" class="headerlink" title="条件概率路径和向量场"></a>条件概率路径和向量场</h3><p>CFM 适用于任何条件概率路径和条件向量场。常用的方法是使用高斯条件概率路径。</p>
<p><strong>高斯条件概率路径：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pt(x|x1) = N(x|µt(x1), σ²t(x1)I)</span><br></pre></td></tr></table></figure>

<p>其中：</p>
<ul>
<li>µt(x1) 是时间 t 的条件均值。</li>
<li>σ²t(x1) 是时间 t 的条件方差。</li>
<li>I 是单位矩阵。</li>
</ul>
<p><strong>条件向量场：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ut(x|x1) = σ&#x27;t(x1) / σt(x1) (x - µt(x1)) + µ&#x27;t(x1)</span><br></pre></td></tr></table></figure>

<p>其中：</p>
<ul>
<li>σ’t(x1) 是 σt(x1) 对时间 t 的导数。</li>
<li>µ’t(x1) 是 µt(x1) 对时间 t 的导数。</li>
</ul>
<h3 id="扩散路径与最优传输-OT-路径"><a href="#扩散路径与最优传输-OT-路径" class="headerlink" title="扩散路径与最优传输 (OT) 路径"></a>扩散路径与最优传输 (OT) 路径</h3><p>扩散路径和最优传输 (OT) 路径是两种常见的用于定义条件概率路径的方法。</p>
<p><strong>扩散路径：</strong></p>
<p>扩散路径使用随机微分方程来定义概率路径。然而，扩散路径可能会导致弯曲的采样轨迹，并且在训练过程中采样成本可能会发生巨大变化。</p>
<p><strong>OT 路径：</strong></p>
<p>OT 路径使用最优传输理论来定义概率路径。OT 路径下的粒子始终以恒定速度沿直线轨迹移动。与扩散路径相比，OT 路径具有以下优势：</p>
<ul>
<li>更简单的采样轨迹</li>
<li>更快的训练速度</li>
<li>更快的生成速度</li>
<li>更好的性能</li>
</ul>
<h3 id="流匹配的应用"><a href="#流匹配的应用" class="headerlink" title="流匹配的应用"></a>流匹配的应用</h3><p>流匹配已成功应用于各种生成建模任务，例如：</p>
<ul>
<li>图像生成</li>
<li>视频生成</li>
<li>音频生成</li>
</ul>
<p><strong>流匹配的优势：</strong></p>
<ul>
<li>可扩展到非常高维度。</li>
<li>提供了一种关于扩散模型的替代观点。</li>
<li>允许更直接地指定概率路径，从而实现更快的采样和&#x2F;或改进生成。</li>
<li>在训练和采样方面都很容易。</li>
</ul>
<p><strong>总结:</strong></p>
<p>流匹配是一种用于训练连续归一化流的强大技术。它提供了一种灵活且可扩展的框架，用于学习从简单分布到复杂数据分布的转换。通过利用条件概率路径和向量场，流匹配避免了昂贵的模拟，并实现了高效的训练和采样。 </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://sergewang.github.io/2024/10/28/%E6%B5%81%E5%8C%B9%E9%85%8D%20(Flow%20Matching)%20%E7%AE%80%E4%BB%8B/" data-id="cm2sm34t1000054vx9fykhtql" data-title="流匹配 (Flow Matching) 简介" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" rel="tag">人工智能</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/" rel="tag">扩散模型</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-计算CNF模型概率的方法" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/10/28/%E8%AE%A1%E7%AE%97CNF%E6%A8%A1%E5%9E%8B%E6%A6%82%E7%8E%87%E7%9A%84%E6%96%B9%E6%B3%95/" class="article-date">
  <time class="dt-published" datetime="2024-10-28T05:51:41.000Z" itemprop="datePublished">2024-10-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Diffusion-Model/">Diffusion Model</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/10/28/%E8%AE%A1%E7%AE%97CNF%E6%A8%A1%E5%9E%8B%E6%A6%82%E7%8E%87%E7%9A%84%E6%96%B9%E6%B3%95/">计算CNF模型概率的方法</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="计算-CNF-模型概率的方法"><a href="#计算-CNF-模型概率的方法" class="headerlink" title="计算 CNF 模型概率的方法"></a>计算 CNF 模型概率的方法</h2><p>连续归一化流 (CNF) 模型通过一个时间依赖的微分同胚映射将简单分布（如标准正态分布）转化为复杂数据分布。要计算 CNF 模型在任意数据点 x1 的概率，我们需要利用连续性方程和流的轨迹方程。</p>
<h3 id="连续性方程和概率密度的变化"><a href="#连续性方程和概率密度的变化" class="headerlink" title="连续性方程和概率密度的变化"></a>连续性方程和概率密度的变化</h3><p>连续性方程描述了概率密度的守恒特性：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d/dt pt(x) + div(pt(x)vt(x)) = 0</span><br></pre></td></tr></table></figure>

<p>其中：</p>
<ul>
<li>pt(x) 是时间 t 的概率密度函数。</li>
<li>vt(x) 是时间 t 的向量场，由 CNF 模型学习得到。</li>
<li>div 是散度算子。</li>
</ul>
<p>这个方程表明，概率密度的变化率必须与其“流动”情况相互抵消，以保证总概率守恒。</p>
<h3 id="计算概率密度的步骤"><a href="#计算概率密度的步骤" class="headerlink" title="计算概率密度的步骤"></a>计算概率密度的步骤</h3><p><strong>步骤 1： 瞬时变量的变化</strong></p>
<p>将连续性方程与流的轨迹方程 (d&#x2F;dt φt(x) &#x3D; vt(φt(x))) 结合，可以得到以下瞬时变量的变化：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d/dt log pt(φt(x)) + div(vt(φt(x)) = 0</span><br></pre></td></tr></table></figure>

<p><strong>步骤 2：积分计算对数概率</strong></p>
<p>对上述方程在时间区间 上积分，得到：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">log p1(φ1(x)) - log p0(φ0(x)) = - ∫ 1</span><br><span class="line">                                    0</span><br><span class="line">                                  div(vt(φt(x)))dt</span><br></pre></td></tr></table></figure>

<p><strong>步骤 3：求解常微分方程</strong></p>
<p>为了计算 log p1(x1)，我们需要求解以下常微分方程 (ODE)：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">d/dt [ φt(x) </span><br><span class="line">       f(t) ] = [ vt(φt(x))</span><br><span class="line">                 -div(vt(φt(x))) ]</span><br></pre></td></tr></table></figure>

<p>其中 f(t) 是一个辅助变量，用于记录 log pt(φt(x)) 的变化。初始条件为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[ φ0(x) </span><br><span class="line">  f(0) ] = [ x0 </span><br><span class="line">            c ]</span><br></pre></td></tr></table></figure>

<p>其中 x0 是初始分布 p0(x) 中的样本，c 是一个常数。</p>
<p><strong>步骤 4：计算最终概率</strong></p>
<p>求解上述 ODE 后，我们可以得到 f(1)。根据步骤 2 中的积分公式，我们可以得到：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f(1) = c + log p1(x1) - log p0(x0)</span><br></pre></td></tr></table></figure>

<p>因此，我们可以计算出 CNF 模型在数据点 x1 的概率密度：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p1(x1) = exp(f(1) - c + log p0(x0))</span><br></pre></td></tr></table></figure>

<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通过利用连续性方程和流的轨迹方程，我们可以推导出计算 CNF 模型在任意数据点 x1 概率密度的方法。这个方法需要求解一个常微分方程，并利用初始条件和积分公式来计算最终的概率密度。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://sergewang.github.io/2024/10/28/%E8%AE%A1%E7%AE%97CNF%E6%A8%A1%E5%9E%8B%E6%A6%82%E7%8E%87%E7%9A%84%E6%96%B9%E6%B3%95/" data-id="cm2slq3x90001j4vx9rej9qkr" data-title="计算CNF模型概率的方法" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" rel="tag">人工智能</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/" rel="tag">扩散模型</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li></ul>

    </footer>
  </div>
  
</article>



  


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archiv</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/10/">十月 2024</a><span class="archive-list-count">5</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">letzter Beitrag</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/10/28/%E5%85%B3%E4%BA%8E-CNF-%E4%B8%AD%E6%97%B6%E9%97%B4%E4%BE%9D%E8%B5%96%E5%BE%AE%E5%88%86%E5%90%8C%E8%83%9A%E6%98%A0%E5%B0%84%E7%9A%84%E7%90%86%E8%A7%A3/">关于 CNF 中时间依赖微分同胚映射的理解</a>
          </li>
        
          <li>
            <a href="/2024/10/28/%E5%AF%B9%E8%BF%9E%E7%BB%AD%E6%80%A7%E6%96%B9%E7%A8%8B%E7%9A%84%E6%B7%B1%E5%85%A5%E8%A7%A3%E8%AF%BB/">对连续性方程的深入解读</a>
          </li>
        
          <li>
            <a href="/2024/10/28/%E8%BF%9E%E7%BB%AD%E6%80%A7%E6%96%B9%E7%A8%8B%E5%9C%A8%E6%B5%81%E5%8C%B9%E9%85%8D%E4%B8%AD%E7%9A%84%E7%90%86%E8%A7%A3/">连续性方程在流匹配中的理解</a>
          </li>
        
          <li>
            <a href="/2024/10/28/%E6%B5%81%E5%8C%B9%E9%85%8D%20(Flow%20Matching)%20%E7%AE%80%E4%BB%8B/">流匹配 (Flow Matching) 简介</a>
          </li>
        
          <li>
            <a href="/2024/10/28/%E8%AE%A1%E7%AE%97CNF%E6%A8%A1%E5%9E%8B%E6%A6%82%E7%8E%87%E7%9A%84%E6%96%B9%E6%B3%95/">计算CNF模型概率的方法</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Kategorien</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Diffusion-Model/">Diffusion Model</a><span class="category-list-count">5</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" rel="tag">人工智能</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/" rel="tag">扩散模型</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a><span class="tag-list-count">5</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" style="font-size: 10px;">人工智能</a> <a href="/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/" style="font-size: 10px;">扩散模型</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">机器学习</a>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 Serge Wang<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>