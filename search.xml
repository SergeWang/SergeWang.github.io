<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>关于 CNF 中时间依赖微分同胚映射的理解</title>
    <url>/2024/10/28/%E5%85%B3%E4%BA%8E-CNF-%E4%B8%AD%E6%97%B6%E9%97%B4%E4%BE%9D%E8%B5%96%E5%BE%AE%E5%88%86%E5%90%8C%E8%83%9A%E6%98%A0%E5%B0%84%E7%9A%84%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<p><img src="/images/bird-wings-flying-feature.gif" alt="关于 CNF 中时间依赖微分同胚映射的理解"></p>
<p>在连续归一化流 (CNF) 中，时间依赖微分同胚映射是将简单分布（如标准正态分布）转化为复杂数据分布的关键机制。它通过一个随时间变化的向量场 \(v_t(x)\) 来实现，这个向量场决定了概率密度函数从初始分布 \(p_\theta(x)\) 到目标分布 \(p_1(x)\) 的演化过程。这个演化过程可以通过一个微分同胚映射 \(\phi_t\) 来描述，它将时间 \(t\) 的概率密度函数 \(p_t(x)\)  “推” 向时间 \(t+dt\) 的概率密度函数 \(p_{t+dt}(x)\)。</p>
<h3 id="微分同胚映射的定义"><a href="#微分同胚映射的定义" class="headerlink" title="微分同胚映射的定义"></a>微分同胚映射的定义</h3><p>微分同胚映射 \(\phi_t\) 拥有以下性质：</p>
<ul>
<li><strong>双射:</strong>  \(\phi_t\) 是一个一一映射，也就是说，对于每一个 x，都有唯一一个 y 与之对应，反之亦然。</li>
<li><strong>可微:</strong>  \(\phi_t\) 和它的逆映射 \(\phi_t^{−1}\)  都是可微的，这意味着它们是光滑且连续的。</li>
<li><strong>保向:</strong>  \(\phi_t\) 保持空间的方向，也就是说，它不会翻转或扭曲空间。</li>
</ul>
<p>这些性质保证了 \(\phi_t\) 可以将一个概率密度函数平滑地转化为另一个概率密度函数，并且不会丢失任何信息。</p>
<h3 id="微分同胚映射的构建"><a href="#微分同胚映射的构建" class="headerlink" title="微分同胚映射的构建"></a>微分同胚映射的构建</h3><p>微分同胚映射 \(\phi_t\) 是通过求解以下常微分方程 (ODE) 得到的:</p>
<p>$$<br>\frac{d}{dt} \phi_t(x) &#x3D; v_t(\phi_t(x))<br>$$<br>$$<br>\phi_0(x) &#x3D; x<br>$$</p>
<p>其中 \(v_t(x)\) 是 CNF 模型学习到的时间依赖向量场。这个 ODE 描述了在向量场 \(v_t(x)\) 的作用下，点 \(x\) 随时间的运动轨迹。\(\phi_tt(x)\)  则表示从初始时刻 \(t&#x3D;0\) 开始，沿着这条轨迹运动到时间 \(t\) 时所到达的点。</p>
<h3 id="连续性方程的作用"><a href="#连续性方程的作用" class="headerlink" title="连续性方程的作用"></a>连续性方程的作用</h3><p>连续性方程可以用来验证向量场  \(v_t(x)\) 是否能够正确地引导概率密度函数的演化。它表明概率密度的变化率必须与其“流动”情况相互抵消，以保证总概率守恒。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>时间依赖微分同胚映射是 CNF 模型的核心概念之一，它通过一个随时间变化的向量场来实现概率密度函数的平滑转化。连续性方程则确保了这个转化过程的有效性。</p>
]]></content>
      <categories>
        <category>Diffusion Model</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>人工智能</tag>
        <tag>扩散模型</tag>
      </tags>
  </entry>
  <entry>
    <title>对连续性方程的深入解读</title>
    <url>/2024/10/28/%E5%AF%B9%E8%BF%9E%E7%BB%AD%E6%80%A7%E6%96%B9%E7%A8%8B%E7%9A%84%E6%B7%B1%E5%85%A5%E8%A7%A3%E8%AF%BB/</url>
    <content><![CDATA[<p>连续性方程本质上是一个描述守恒量的方程。在流匹配的语境下，这个守恒量就是概率密度。 </p>
<h3 id="概率密度的守恒"><a href="#概率密度的守恒" class="headerlink" title="概率密度的守恒"></a>概率密度的守恒</h3><p>想象一下液体在管道中流动。如果液体不可压缩，那么无论管道粗细如何变化，单位时间内流过任何一个截面的液体总量都应该保持不变。这就是质量守恒定律的体现。</p>
<p>概率密度也遵循类似的守恒原则。假设我们有一个概率密度函数 \(p_t(x)\)，它描述了在时间 \(t\) 时，随机变量 \(X\) 取值 \(x\) 的概率密度。随着时间的推移，\(p_t(x)\) 的形状可能会发生变化，但它所代表的总概率必须保持为 1。</p>
<p>连续性方程正是用来描述概率密度这种守恒特性的数学工具。</p>
<h3 id="连续性方程的数学表达"><a href="#连续性方程的数学表达" class="headerlink" title="连续性方程的数学表达"></a>连续性方程的数学表达</h3><p>连续性方程的表达式如下：</p>
<p>$$<br>\frac{d}{dt} p_t(x) + div(p_t(x)v_t(x)) &#x3D; 0<br>$$</p>
<ul>
<li><strong>\(\frac{d}{dt} p_t(x)\)</strong> 表示概率密度函数 \(p_t(x)\) 随时间的变化率。</li>
<li><strong>\(div(p_t(x)v_t(x))\)</strong> 表示概率密度的“流动”情况，其中 \(v_t(x)\) 是一个向量场，描述了概率密度在空间中的运动方向和速度。散度算子 \(div\) 则度量了向量场在某一点的“扩张”或“收缩”程度。</li>
</ul>
<p><strong>连续性方程的意义：</strong></p>
<ul>
<li>如果 \(\frac{d}{dt} p_t(x)\) 为正，说明在 x 点的概率密度正在增加，这可能是由于周围的概率密度流入了 \(x\) 点。</li>
<li>如果 \(div(p_t(x)v_t(x))\) 为负，说明在 x 点的概率密度正在减少，这可能是由于 \(x\) 点的概率密度流向了周围。</li>
</ul>
<p>连续性方程指出，概率密度的变化率与概率密度的“流动”情况必须相互抵消，以保证总概率守恒。</p>
<h3 id="连续性方程在流匹配中的应用"><a href="#连续性方程在流匹配中的应用" class="headerlink" title="连续性方程在流匹配中的应用"></a>连续性方程在流匹配中的应用</h3><p>在流匹配中，我们希望训练一个连续归一化流 (CNF) 模型，使其能够生成与目标数据分布相似的样本。这个 CNF 模型可以用一个向量场 \(v_t(x)\) 来表示，它决定了概率密度函数从初始分布 \(p_0(x)\) 到目标分布 \(p_1(x)\) 的演化过程。</p>
<p>连续性方程的作用就是确保 CNF 模型所定义的向量场 \(v_t(x)\) 能够正确地引导概率密度函数的演化，并最终生成我们期望的目标分布。</p>
<p><strong>具体来说，连续性方程的应用体现在以下几个方面：</strong></p>
<ol>
<li><strong>验证模型的有效性：</strong> 通过检查学习到的向量场 \(v_t(x)\) 是否满足连续性方程，我们可以判断 CNF 模型是否能够生成有效的概率路径。</li>
<li><strong>设计训练目标函数：</strong>  一些流匹配的训练目标函数的设计是基于连续性方程的。例如，条件流匹配 (CFM) 的目标函数就是为了最小化模型向量场与目标向量场之间的差异，而目标向量场的构建正是基于连续性方程。</li>
<li><strong>计算模型的概率密度：</strong> 利用连续性方程和流的轨迹方程，我们可以推导出计算 CNF 模型在任意数据点概率密度的方法。</li>
</ol>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>连续性方程是理解流匹配的关键概念之一。它提供了一种数学工具来描述概率密度的守恒特性，并确保 CNF 模型能够生成有效的概率路径。 </p>
]]></content>
      <categories>
        <category>Diffusion Model</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>人工智能</tag>
        <tag>扩散模型</tag>
      </tags>
  </entry>
  <entry>
    <title>主要扩散模型及其相关类别</title>
    <url>/2024/10/28/%E4%B8%BB%E8%A6%81%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E5%8F%8A%E5%85%B6%E7%9B%B8%E5%85%B3%E7%B1%BB%E5%88%AB/</url>
    <content><![CDATA[<p><img src="/images/diffusion-models.png" alt="主要扩散模型"></p>
<h2 id="1-基于分数匹配的扩散模型"><a href="#1-基于分数匹配的扩散模型" class="headerlink" title="1.基于分数匹配的扩散模型"></a>1.基于分数匹配的扩散模型</h2><p>● 噪声条件评分网络 (NCSN): 这是一种早期的基于分数匹配的扩散模型，它使用神经网络来学习数据分布的评分函数。<br>● 潜空间评分生成模型 (LSGM): LSGM 使用变分自编码器 (VAE) 将数据压缩到潜空间，然后在潜空间中应用评分匹配来学习数据分布。<br>● 基于分数的随机微分方程 (Score-SDE): Score-SDE 使用随机微分方程 (SDE) 来描述扩散过程，并使用神经网络来学习 SDE 的漂移项，该漂移项与数据分布的评分函数相关。<br>● ScoreFlow: ScoreFlow 通过最大化似然函数的上界来训练基于分数的扩散模型。</p>
<h2 id="2-潜变量模型"><a href="#2-潜变量模型" class="headerlink" title="2.潜变量模型"></a>2.潜变量模型</h2><p>● 潜扩散模型 (LDM): LDM 使用预训练的 VAE 将图像压缩到潜空间，然后在潜空间中应用扩散模型来生成图像。这种方法可以提高训练和推理效率，并生成更高质量的图像。</p>
<h2 id="3-条件引导的扩散模型"><a href="#3-条件引导的扩散模型" class="headerlink" title="3.条件引导的扩散模型"></a>3.条件引导的扩散模型</h2><p>● 引导扩散 (GLIDE): GLIDE 使用分类器引导来控制扩散模型的生成过程，使其生成符合特定条件的图像。<br>● 分类器引导扩散 (CfDG): CfDG 是一种改进的分类器引导方法，它可以更有效地将条件信息整合到扩散模型中。<br>● 稳定扩散 (Stable Diffusion): Stable Diffusion 是一种流行的文本到图像扩散模型，它使用 LDM 和 CfDG 来生成高质量的图像。</p>
<h2 id="4-基于-Transformer-的扩散模型"><a href="#4-基于-Transformer-的扩散模型" class="headerlink" title="4.基于 Transformer 的扩散模型"></a>4.基于 Transformer 的扩散模型</h2><p>● U-ViT: U-ViT 将 Transformer 模块引入到 U 形结构中，作为扩散模型的主干网络，它将所有输入视为 token，并在浅层和深层之间使用长跳跃连接。<br>● 扩散 Transformer (DiT): DiT 使用视觉 Transformer (ViT) 作为主干网络来代替 U-Net，并进一步证明了 Transformer 在图像生成任务中的可扩展性。<br>● PixArt-α: PixArt-α 简化了扩散 Transformer 中计算密集的类条件分支，方法是加入交叉注意模块来注入通过 T5 编码的文本条件。</p>
<h2 id="5-基于状态空间模型-SSM-的扩散模型"><a href="#5-基于状态空间模型-SSM-的扩散模型" class="headerlink" title="5.基于状态空间模型 (SSM) 的扩散模型"></a>5.基于状态空间模型 (SSM) 的扩散模型</h2><p>● Mamba: Mamba 结合了 SSM 架构，并提出了硬件感知算法，可实现高效的训练和推理。<br>● DiM: DiM 引入 Mamba 作为扩散主干网络，用于生成高分辨率图像。<br>● ZigMa: ZigMa 通过在图像中加入基于连续性的归纳偏差，使 Mamba 模块适用于二维图像，并通过执行三维序列的时空分解，将其扩展到视频生成任务。<br>类别之间的关系:<br>这些类别之间存在着一些联系。例如，许多基于分数匹配的扩散模型也使用了潜变量模型，例如 LSGM 和 LDM。条件引导的扩散模型可以使用各种主干网络，包括基于 U-Net、Transformer 或 SSM 的网络。</p>
]]></content>
      <categories>
        <category>Diffusion Model</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>人工智能</tag>
        <tag>扩散模型</tag>
      </tags>
  </entry>
  <entry>
    <title>流匹配 (Flow Matching) 简介</title>
    <url>/2024/10/28/%E6%B5%81%E5%8C%B9%E9%85%8D%20(Flow%20Matching)%20%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<p>流匹配 (FM) 是一种用于训练连续归一化流 (CNF) 的新方法，它能够以空前的规模训练 CNF。它基于一种称为“条件概率路径”的概念，该路径描述了从噪声样本到数据样本的转换过程。FM 的目标是通过回归固定条件概率路径的向量场来匹配该目标概率路径，而无需进行昂贵的模拟。</p>
<h3 id="条件流匹配-CFM"><a href="#条件流匹配-CFM" class="headerlink" title="条件流匹配 (CFM)"></a>条件流匹配 (CFM)</h3><p>为了使 FM 更加易于处理，引入了条件流匹配 (CFM) 的概念。CFM 避免了对难以处理的积分的依赖，并使用每个样本定义的概率路径和向量场。</p>
<p><strong>CFM 目标函数：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">LCFM(θ) = Et,q(x1),p(x0) ||| vt(ψt(x0)) - d/dt ψt(x0) |||² </span><br></pre></td></tr></table></figure>

<p>其中：</p>
<ul>
<li>θ 是 CNF 向量场的可学习参数。</li>
<li>t ∼ U（均匀分布）。</li>
<li>x1 是服从未知数据分布 q(x1) 的随机变量。</li>
<li>x0 ∼ p(x0) 是服从简单分布的随机变量，例如标准正态分布。</li>
<li>ψt 是与条件概率路径 pt(x|x1) 对应的流映射。</li>
<li>vt 是 CNF 向量场。</li>
</ul>
<p><strong>CFM 的优势：</strong></p>
<ul>
<li>与原始 FM 目标函数具有相同的最佳值。</li>
<li>不需要显式了解难以处理的目标向量场。</li>
</ul>
<h3 id="条件概率路径和向量场"><a href="#条件概率路径和向量场" class="headerlink" title="条件概率路径和向量场"></a>条件概率路径和向量场</h3><p>CFM 适用于任何条件概率路径和条件向量场。常用的方法是使用高斯条件概率路径。</p>
<p><strong>高斯条件概率路径：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pt(x|x1) = N(x|µt(x1), σ²t(x1)I)</span><br></pre></td></tr></table></figure>

<p>其中：</p>
<ul>
<li>µt(x1) 是时间 t 的条件均值。</li>
<li>σ²t(x1) 是时间 t 的条件方差。</li>
<li>I 是单位矩阵。</li>
</ul>
<p><strong>条件向量场：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ut(x|x1) = σ&#x27;t(x1) / σt(x1) (x - µt(x1)) + µ&#x27;t(x1)</span><br></pre></td></tr></table></figure>

<p>其中：</p>
<ul>
<li>σ’t(x1) 是 σt(x1) 对时间 t 的导数。</li>
<li>µ’t(x1) 是 µt(x1) 对时间 t 的导数。</li>
</ul>
<h3 id="扩散路径与最优传输-OT-路径"><a href="#扩散路径与最优传输-OT-路径" class="headerlink" title="扩散路径与最优传输 (OT) 路径"></a>扩散路径与最优传输 (OT) 路径</h3><p>扩散路径和最优传输 (OT) 路径是两种常见的用于定义条件概率路径的方法。</p>
<p><strong>扩散路径：</strong></p>
<p>扩散路径使用随机微分方程来定义概率路径。然而，扩散路径可能会导致弯曲的采样轨迹，并且在训练过程中采样成本可能会发生巨大变化。</p>
<p><strong>OT 路径：</strong></p>
<p>OT 路径使用最优传输理论来定义概率路径。OT 路径下的粒子始终以恒定速度沿直线轨迹移动。与扩散路径相比，OT 路径具有以下优势：</p>
<ul>
<li>更简单的采样轨迹</li>
<li>更快的训练速度</li>
<li>更快的生成速度</li>
<li>更好的性能</li>
</ul>
<h3 id="流匹配的应用"><a href="#流匹配的应用" class="headerlink" title="流匹配的应用"></a>流匹配的应用</h3><p>流匹配已成功应用于各种生成建模任务，例如：</p>
<ul>
<li>图像生成</li>
<li>视频生成</li>
<li>音频生成</li>
</ul>
<p><strong>流匹配的优势：</strong></p>
<ul>
<li>可扩展到非常高维度。</li>
<li>提供了一种关于扩散模型的替代观点。</li>
<li>允许更直接地指定概率路径，从而实现更快的采样和&#x2F;或改进生成。</li>
<li>在训练和采样方面都很容易。</li>
</ul>
<p><strong>总结:</strong></p>
<p>流匹配是一种用于训练连续归一化流的强大技术。它提供了一种灵活且可扩展的框架，用于学习从简单分布到复杂数据分布的转换。通过利用条件概率路径和向量场，流匹配避免了昂贵的模拟，并实现了高效的训练和采样。 </p>
]]></content>
      <categories>
        <category>Diffusion Model</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>人工智能</tag>
        <tag>扩散模型</tag>
      </tags>
  </entry>
  <entry>
    <title>计算CNF模型概率的方法</title>
    <url>/2024/10/28/%E8%AE%A1%E7%AE%97CNF%E6%A8%A1%E5%9E%8B%E6%A6%82%E7%8E%87%E7%9A%84%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>连续归一化流 (CNF) 模型通过一个时间依赖的微分同胚映射将简单分布（如标准正态分布）转化为复杂数据分布。要计算 CNF 模型在任意数据点 \(x_1\) 的概率，我们需要利用连续性方程和流的轨迹方程。</p>
<h3 id="连续性方程和概率密度的变化"><a href="#连续性方程和概率密度的变化" class="headerlink" title="连续性方程和概率密度的变化"></a>连续性方程和概率密度的变化</h3><p>连续性方程描述了概率密度的守恒特性：</p>
<!-- <p>
  When \(a \ne 0\), there are two solutions to \(ax^2 + bx + c = 0\) and they are
  \[x = {-b \pm \sqrt{b^2-4ac} \over 2a}.\]
</p> -->

<!-- \\(\mathcal{F}(x)=\mathcal{H}(x)-x\\) -->


<!-- $$\lim_{n\rightarrow \infty}(1+2^n+3^n)^\frac{1}{x+\sin n}$$ -->

<!-- <p>
\[\frac{d}{dt}p_t(x) + div(p_t(x)v_t(x)) = 0\]
</p> -->

<p>$$\frac{d}{dt}p_t(x) + div(p_t(x)v_t(x)) &#x3D; 0$$</p>
<p>其中：</p>
<ul>
<li>\(p_t(x)\) 是时间 t 的概率密度函数。</li>
<li>\(v_t(x)\) 是时间 t 的向量场，由 CNF 模型学习得到。</li>
<li>\(div\) 是散度算子。</li>
</ul>
<p>这个方程表明，概率密度的变化率必须与其“流动”情况相互抵消，以保证总概率守恒。</p>
<h3 id="计算概率密度的步骤"><a href="#计算概率密度的步骤" class="headerlink" title="计算概率密度的步骤"></a>计算概率密度的步骤</h3><p><strong>步骤 1： 瞬时变量的变化</strong></p>
<p>将连续性方程与流的轨迹方程 (\(\frac{d}{dt}\phi_t(x) &#x3D; v_t(\phi_t(x))\)) 结合，可以得到以下瞬时变量的变化：</p>
<p>$$\frac{d}{dt}\log p_t(\phi_t(x)) + div(v_t(\phi_t(x)) &#x3D; 0$$</p>
<p><strong>步骤 2：积分计算对数概率</strong></p>
<p>对上述方程在时间区间[0,1]上积分，得到：</p>
<p>$$<br>\log p_1(\phi_1(x)) - \log p_0(\phi_0(x)) &#x3D; -\int^1_0 div(v_t(\phi_t(x)))dt<br>$$</p>
<p><strong>步骤 3：求解常微分方程</strong></p>
<p>为了计算 \(\log p_1(x_1)\)，我们需要求解以下常微分方程 (ODE)：</p>
<p>$$<br>\frac{d}{dt}\begin{bmatrix}\phi_t(x)\cr f(t)\end{bmatrix} &#x3D; \begin{bmatrix}v_t(\phi_t(x))\cr -div(v_t(\phi_t(x)))\end{bmatrix}<br>$$</p>
<p>其中 \(f(t)\) 是一个辅助变量，用于记录 \(\log p_t(\phi_t(x))\) 的变化。初始条件为：<br>$$<br>\begin{bmatrix}\phi_0(x)\cr f(0)\end{bmatrix} &#x3D; \begin{bmatrix}x_0\cr c\end{bmatrix}<br>$$</p>
<p>其中 \(x_0\) 是初始分布 \(p_0(x) \)中的样本，\(c\) 是一个常数。</p>
<p><strong>步骤 4：计算最终概率</strong></p>
<p>求解上述 ODE 后，我们可以得到 \(f(1)\)。根据步骤 2 中的积分公式，我们可以得到：</p>
<p>$$<br>f(1) &#x3D; c + \log p_1(x_1) - \log p_0(x_0)<br>$$</p>
<p>因此，我们可以计算出 CNF 模型在数据点 \(x_1\) 的概率密度：</p>
<p>$$<br>p_1(x_1) &#x3D; exp(f(1) - c + \log p_0(x_0))<br>$$</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通过利用连续性方程和流的轨迹方程，我们可以推导出计算 CNF 模型在任意数据点 x1 概率密度的方法。这个方法需要求解一个常微分方程，并利用初始条件和积分公式来计算最终的概率密度。</p>
]]></content>
      <categories>
        <category>Diffusion Model</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>人工智能</tag>
        <tag>扩散模型</tag>
      </tags>
  </entry>
  <entry>
    <title>连续性方程在流匹配中的理解</title>
    <url>/2024/10/28/%E8%BF%9E%E7%BB%AD%E6%80%A7%E6%96%B9%E7%A8%8B%E5%9C%A8%E6%B5%81%E5%8C%B9%E9%85%8D%E4%B8%AD%E7%9A%84%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<!-- <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> -->
<p>连续性方程是偏微分方程 (PDE)，它提供了一个必要且充分的条件，以确保向量场 \(v_t\) 生成概率路径 \(pt\)。 换句话说，它验证了给定的向量场是否确实生成了期望的概率密度演变。</p>
<p><strong>连续性方程：</strong></p>
<p>$$<br>\frac{d}{dt} p_t(x) + div(p_t(x)v_t(x)) &#x3D; 0<br>$$</p>
<p>其中：</p>
<ul>
<li>\(p_t(x)\) 是时间 \(t\) 的概率密度函数。</li>
<li>\(v_t(x)\) 是时间 \(t\) 的向量场。</li>
<li>\(div\) 是关于空间变量 \(x &#x3D; (x^1, …, x^d)\) 的散度算子，即  \(div &#x3D; \sum_{i&#x3D;1}^d \frac{\partial}{\partial x^i}\) 。</li>
</ul>
<p><strong>连续性方程在流匹配中的作用：</strong></p>
<ul>
<li><strong>验证向量场：</strong> 连续性方程用于检验学习到的 CNF 模型的向量场 \(v_t\) 是否确实生成了目标概率路径 \(p_t(x)\)。</li>
<li><strong>证明定理：</strong> 在证明流匹配的相关定理时，连续性方程起着关键作用。例如，在定理 1 的证明中，通过验证边际概率路径 \(p_t\) 和边际向量场 \(u_t\) 满足连续性方程，可以证明 \(u_t\) 确实生成了 \(p_t\)。</li>
</ul>
<p><strong>计算 CNF 模型的概率：</strong></p>
<p>连续性方程与流动的轨迹方程 (\(\frac{d}{dt} \phi_t(x) &#x3D; v_t(\phi_t(x))\)) 结合，可以推导出瞬时变量的变化，并最终得到计算 CNF 模型在任意数据点 \(x_1\) 概率的方法。</p>
<p><strong>总结:</strong></p>
<p>连续性方程在流匹配中扮演着重要的角色，它不仅用于验证向量场，还在理论证明和概率计算中发挥着关键作用。 </p>
]]></content>
      <categories>
        <category>Diffusion Model</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>人工智能</tag>
        <tag>扩散模型</tag>
      </tags>
  </entry>
</search>
